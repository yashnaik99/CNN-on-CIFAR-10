{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "knRpYoAnwr1c"
   },
   "source": [
    "# Implement DenseNet on CIFAR-10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index\n",
    "\n",
    "1. Assignment instructions\n",
    "\n",
    "\n",
    "\n",
    "2. Assignment\n",
    " - 2.1 Defining Dense Block, Transition Block and Output Block\n",
    " - 2.2 Using Data Augmentation for training the DenseNet\n",
    " - 2.3 Using LearningRateScheduler, ReduceLRonPlateau,CSVLogger in callbacks\n",
    " - 2.4 Growth Rate(num_filter) = 36, compression = 0.7, Number of blocks = 12\n",
    " - 2.5 Plotting loss and accuracy of Model 5 above\n",
    "\n",
    "\n",
    "3. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dVbwx0fewziM"
   },
   "source": [
    "## 1. Assignment instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ucjyE-mnxAVC"
   },
   "source": [
    "1.  Please visit this link to access the state-of-art DenseNet code for reference - DenseNet - cifar10 notebook link\n",
    "2.  You need to create a copy of this and \"retrain\" this model to achieve 90+ test accuracy. \n",
    "3.  You cannot use DropOut layers.\n",
    "4.  You MUST use Image Augmentation Techniques.\n",
    "5.  You cannot use an already trained model as a beginning points, you have to initilize as your own\n",
    "6.  You cannot run the program for more than 300 Epochs, and it should be clear from your log, that you have only used 300 Epochs\n",
    "7.  You cannot use test images for training the model.\n",
    "8.  You cannot change the general architecture of DenseNet (which means you must use Dense Block, Transition and Output blocks as mentioned in the code)\n",
    "9.  You are free to change Convolution types (e.g. from 3x3 normal convolution to Depthwise Separable, etc)\n",
    "10. You cannot have more than 1 Million parameters in total\n",
    "11. You are free to move the code from Keras to Tensorflow, Pytorch, MXNET etc. \n",
    "12. You can use any optimization algorithm you need. \n",
    "13. You can checkpoint your model and retrain the model from that checkpoint so that no need of training the model from first if you lost at any epoch while training. You can directly load that model and Train from that epoch. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ALdcoVTVy9hd"
   },
   "source": [
    "## 2. Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gbII1-uhfMG0"
   },
   "outputs": [],
   "source": [
    "# import keras\n",
    "# from keras.datasets import cifar10\n",
    "# from keras.models import Model, Sequential\n",
    "# from keras.layers import Dense, Dropout, Flatten, Input, AveragePooling2D, merge, Activation\n",
    "# from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "# from keras.layers import Concatenate\n",
    "# from keras.optimizers import Adam\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation, Flatten\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vZjxA5HWf5RN"
   },
   "outputs": [],
   "source": [
    "# this part will prevent tensorflow to allocate all the avaliable GPU Memory\n",
    "# backend\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b2xm8NSqf5L-",
    "outputId": "d21e6cad-55d4-4fc5-9b80-7f59746d8352"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Load CIFAR10 Data\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "img_height, img_width, channel = X_train.shape[1],X_train.shape[2],X_train.shape[3]\n",
    "\n",
    "#scale the data (images) to [0,1] range\n",
    "X_train = X_train.astype(\"float32\")/255\n",
    "X_test = X_test.astype(\"float32\")/255\n",
    "\n",
    "# convert to one hot encoding\n",
    "num_classes = 10 \n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QypLwCjlf5JX",
    "outputId": "e94fe5fc-a293-45b3-c3d0-ddc1e0eba5cc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FFY6o1C4f5Gn",
    "outputId": "5f313e82-13c0-4d43-b557-b35baac9ffd4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 32, 32, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g-HDwYenzMOY"
   },
   "source": [
    "### 2.1 Defining Dense Block, Transition Block and Output Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ttgY82f1f5D_"
   },
   "outputs": [],
   "source": [
    "# Dense Block\n",
    "def denseblock(input, num_filter = 12, dropout_rate = 0.2):\n",
    "    global compression\n",
    "    temp = input\n",
    "    for _ in range(l): \n",
    "        BatchNorm = layers.BatchNormalization()(temp)\n",
    "        relu = layers.Activation('relu')(BatchNorm)\n",
    "        Conv2D_1_1 = layers.Conv2D(int(num_filter*compression), (1,1),use_bias=False,padding='same')(relu)\n",
    "        BatchNorm1 = layers.BatchNormalization()(Conv2D_1_1)\n",
    "        relu1 = layers.Activation('relu')(BatchNorm1)\n",
    "        Conv2D_3_3 = layers.Conv2D(int(num_filter*compression), (3,3), use_bias=False ,padding='same')(relu1)\n",
    "        if dropout_rate>0:\n",
    "            Conv2D_3_3 = layers.Dropout(dropout_rate)(Conv2D_3_3)\n",
    "        concat = layers.Concatenate(axis=-1)([temp,Conv2D_3_3])\n",
    "        \n",
    "        temp = concat\n",
    "        \n",
    "    return temp\n",
    "\n",
    "## transition Block\n",
    "def transition(input, num_filter = 12, dropout_rate = 0.2):\n",
    "    global compression\n",
    "    BatchNorm = layers.BatchNormalization()(input)\n",
    "    relu = layers.Activation('relu')(BatchNorm)\n",
    "    Conv2D_BottleNeck = layers.Conv2D(int(num_filter*compression), (1,1), use_bias=False ,padding='same')(relu)\n",
    "    if dropout_rate>0:\n",
    "         Conv2D_BottleNeck = layers.Dropout(dropout_rate)(Conv2D_BottleNeck)\n",
    "    avg = layers.AveragePooling2D(pool_size=(2,2))(Conv2D_BottleNeck)\n",
    "    return avg\n",
    "\n",
    "#output layer\n",
    "def output_layer(input):\n",
    "    global compression\n",
    "    BatchNorm = layers.BatchNormalization()(input)\n",
    "    relu = layers.Activation('relu')(BatchNorm)\n",
    "    AvgPooling = layers.AveragePooling2D(pool_size=(2,2))(relu)\n",
    "    flat = layers.Flatten()(AvgPooling)\n",
    "    output = layers.Dense(num_classes, activation='softmax')(flat)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wFJlaX9I2jVk"
   },
   "source": [
    "### 2.2 Using Data Augmentation for training the DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nY4LGoBX03jm"
   },
   "outputs": [],
   "source": [
    "#https://www.pyimagesearch.com/2018/12/24/how-to-use-keras-fit-and-fit_generator-a-hands-on-tutorial/\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "#creating a training image generator for data augmentation\n",
    "aug = ImageDataGenerator(rotation_range=0.20,width_shift_range=0.20,height_shift_range=0.15,shear_range=0.15,\n",
    "                         zoom_range=0.30,horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0kB5h_nA1NuD"
   },
   "source": [
    "### 2.3 Using LearningRateScheduler, ReduceLRonPlateau,CSVLogger in callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e-wqw66X02v2"
   },
   "outputs": [],
   "source": [
    "#https://keras.io/api/callbacks/reduce_lr_on_plateau/\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BKwSPFlx02s7"
   },
   "outputs": [],
   "source": [
    "#https://keras.io/api/callbacks/learning_rate_scheduler/\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "lr_list = [0.01,0.001,0.0001]\n",
    "def scheduler(epoch,lr):\n",
    "  if epoch<25:\n",
    "    return lr_list[0]\n",
    "  if epoch>=25 and epoch<50:\n",
    "    return lr_list[1]\n",
    "  else:\n",
    "    return lr_list[2]\n",
    "\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "umUN12qx02qK"
   },
   "outputs": [],
   "source": [
    "#https://keras.io/api/callbacks/csv_logger/\n",
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "\n",
    "csv_logger = CSVLogger('training.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7RuU_YEI9Cc7"
   },
   "outputs": [],
   "source": [
    "#https://keras.io/api/callbacks/early_stopping/\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stop = EarlyStopping(monitor='loss',patience=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H-rgEuzuUyys"
   },
   "source": [
    "### 2.4 Growth Rate(num_filter) = 36, compression = 0.7, Number of blocks = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 64\n",
    "num_classes = 10\n",
    "nb_epoch = 100\n",
    "l = 12\n",
    "num_filter = 36\n",
    "compression = 0.7\n",
    "dropout_rate = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "#https://machinelearningmastery.com/check-point-deep-learning-models-keras/\n",
    "filepath=\"model5_weights.best.hdf5\"\n",
    "model_checkpoint = ModelCheckpoint(filepath,monitor='val_accuracy',save_best_only=True,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = layers.Input(shape=(img_height, img_width, channel,))\n",
    "First_Conv2D = layers.Conv2D(num_filter, (3,3), use_bias=False ,padding='same')(input)\n",
    "\n",
    "First_Block = denseblock(First_Conv2D, num_filter, dropout_rate)\n",
    "First_Transition = transition(First_Block, num_filter, dropout_rate)\n",
    "\n",
    "Second_Block = denseblock(First_Transition, num_filter, dropout_rate)\n",
    "Second_Transition = transition(Second_Block, num_filter, dropout_rate)\n",
    "\n",
    "Third_Block = denseblock(Second_Transition, num_filter, dropout_rate)\n",
    "Third_Transition = transition(Third_Block, num_filter, dropout_rate)\n",
    "\n",
    "Last_Block = denseblock(Third_Transition,  num_filter, dropout_rate)\n",
    "output = output_layer(Last_Block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-l-Rrz_neUGB",
    "outputId": "7fd1fec8-54ec-452a-e9b8-b30d1cb4a624"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 32, 32, 36)   972         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 32, 32, 36)   144         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 32, 32, 36)   0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 32, 32, 25)   900         activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 32, 25)   100         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 32, 32, 25)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 25)   5625        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 32, 32, 61)   0           conv2d[0][0]                     \n",
      "                                                                 conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 61)   244         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 32, 32, 61)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 32, 25)   1525        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 32, 25)   100         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 32, 32, 25)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 32, 32, 25)   5625        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 32, 32, 86)   0           concatenate[0][0]                \n",
      "                                                                 conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 32, 32, 86)   344         concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 32, 32, 86)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 32, 32, 25)   2150        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32, 32, 25)   100         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 32, 32, 25)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 25)   5625        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 32, 32, 111)  0           concatenate_1[0][0]              \n",
      "                                                                 conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 32, 32, 111)  444         concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 32, 32, 111)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 25)   2775        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 32, 32, 25)   100         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 32, 32, 25)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 25)   5625        activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 32, 32, 136)  0           concatenate_2[0][0]              \n",
      "                                                                 conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 32, 136)  544         concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 32, 32, 136)  0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 25)   3400        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 32, 32, 25)   100         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 32, 32, 25)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 32, 32, 25)   5625        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 32, 32, 161)  0           concatenate_3[0][0]              \n",
      "                                                                 conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 32, 32, 161)  644         concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 32, 32, 161)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 32, 32, 25)   4025        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 32, 32, 25)   100         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 32, 32, 25)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 32, 32, 25)   5625        activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 32, 32, 186)  0           concatenate_4[0][0]              \n",
      "                                                                 conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 32, 32, 186)  744         concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 32, 32, 186)  0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 32, 32, 25)   4650        activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 32, 32, 25)   100         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 32, 32, 25)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 32, 32, 25)   5625        activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 32, 32, 211)  0           concatenate_5[0][0]              \n",
      "                                                                 conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 32, 32, 211)  844         concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 32, 32, 211)  0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 32, 32, 25)   5275        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 32, 32, 25)   100         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 32, 32, 25)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 32, 32, 25)   5625        activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 32, 32, 236)  0           concatenate_6[0][0]              \n",
      "                                                                 conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 32, 32, 236)  944         concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 32, 32, 236)  0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 32, 32, 25)   5900        activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 32, 32, 25)   100         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 32, 32, 25)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 32, 32, 25)   5625        activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 32, 32, 261)  0           concatenate_7[0][0]              \n",
      "                                                                 conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 32, 32, 261)  1044        concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 32, 32, 261)  0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 32, 32, 25)   6525        activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 32, 32, 25)   100         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 32, 32, 25)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 32, 32, 25)   5625        activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 32, 32, 286)  0           concatenate_8[0][0]              \n",
      "                                                                 conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 32, 32, 286)  1144        concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 32, 32, 286)  0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 32, 32, 25)   7150        activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 32, 32, 25)   100         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 32, 32, 25)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 32, 32, 25)   5625        activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 32, 32, 311)  0           concatenate_9[0][0]              \n",
      "                                                                 conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 32, 32, 311)  1244        concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 32, 32, 311)  0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 32, 32, 25)   7775        activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 32, 32, 25)   100         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 32, 32, 25)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 32, 32, 25)   5625        activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 32, 32, 336)  0           concatenate_10[0][0]             \n",
      "                                                                 conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 32, 32, 336)  1344        concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 32, 32, 336)  0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 32, 32, 25)   8400        activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 16, 16, 25)   0           conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 16, 16, 25)   100         average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 16, 16, 25)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 16, 16, 25)   625         activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 16, 16, 25)   100         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 16, 16, 25)   0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 16, 16, 25)   5625        activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 16, 16, 50)   0           average_pooling2d[0][0]          \n",
      "                                                                 conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 16, 16, 50)   200         concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 16, 16, 50)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 16, 16, 25)   1250        activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 16, 16, 25)   100         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 16, 16, 25)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 16, 16, 25)   5625        activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 16, 16, 75)   0           concatenate_12[0][0]             \n",
      "                                                                 conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 16, 16, 75)   300         concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 16, 16, 75)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 16, 16, 25)   1875        activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 16, 16, 25)   100         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 16, 16, 25)   0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 16, 16, 25)   5625        activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 16, 16, 100)  0           concatenate_13[0][0]             \n",
      "                                                                 conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 16, 16, 100)  400         concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 16, 16, 100)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 16, 16, 25)   2500        activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 16, 16, 25)   100         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 16, 16, 25)   0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 16, 16, 25)   5625        activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 16, 16, 125)  0           concatenate_14[0][0]             \n",
      "                                                                 conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 16, 16, 125)  500         concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 16, 16, 125)  0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 16, 16, 25)   3125        activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 16, 16, 25)   100         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 16, 16, 25)   0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 16, 16, 25)   5625        activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 16, 16, 150)  0           concatenate_15[0][0]             \n",
      "                                                                 conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 16, 16, 150)  600         concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 16, 16, 150)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 16, 16, 25)   3750        activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 16, 16, 25)   100         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 16, 16, 25)   0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 16, 16, 25)   5625        activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, 16, 16, 175)  0           concatenate_16[0][0]             \n",
      "                                                                 conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 16, 16, 175)  700         concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 16, 16, 175)  0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 16, 16, 25)   4375        activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 16, 16, 25)   100         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 16, 16, 25)   0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 16, 16, 25)   5625        activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, 16, 16, 200)  0           concatenate_17[0][0]             \n",
      "                                                                 conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 16, 16, 200)  800         concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 16, 16, 200)  0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 16, 16, 25)   5000        activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 16, 16, 25)   100         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 16, 16, 25)   0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 16, 16, 25)   5625        activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, 16, 16, 225)  0           concatenate_18[0][0]             \n",
      "                                                                 conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 16, 16, 225)  900         concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 16, 16, 225)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 16, 16, 25)   5625        activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 16, 16, 25)   100         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 16, 16, 25)   0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 16, 16, 25)   5625        activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_20 (Concatenate)    (None, 16, 16, 250)  0           concatenate_19[0][0]             \n",
      "                                                                 conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 16, 16, 250)  1000        concatenate_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 16, 16, 250)  0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 16, 16, 25)   6250        activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 16, 16, 25)   100         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 16, 16, 25)   0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 16, 16, 25)   5625        activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_21 (Concatenate)    (None, 16, 16, 275)  0           concatenate_20[0][0]             \n",
      "                                                                 conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 16, 16, 275)  1100        concatenate_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 16, 16, 275)  0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 16, 16, 25)   6875        activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 16, 16, 25)   100         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 16, 16, 25)   0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 16, 16, 25)   5625        activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_22 (Concatenate)    (None, 16, 16, 300)  0           concatenate_21[0][0]             \n",
      "                                                                 conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 16, 16, 300)  1200        concatenate_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 16, 16, 300)  0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 16, 16, 25)   7500        activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 16, 16, 25)   100         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 16, 16, 25)   0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 16, 16, 25)   5625        activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_23 (Concatenate)    (None, 16, 16, 325)  0           concatenate_22[0][0]             \n",
      "                                                                 conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 16, 16, 325)  1300        concatenate_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 16, 16, 325)  0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 16, 16, 25)   8125        activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 8, 8, 25)     0           conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 8, 8, 25)     100         average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 8, 8, 25)     0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 8, 8, 25)     625         activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 8, 8, 25)     100         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 8, 8, 25)     0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 8, 8, 25)     5625        activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_24 (Concatenate)    (None, 8, 8, 50)     0           average_pooling2d_1[0][0]        \n",
      "                                                                 conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 8, 8, 50)     200         concatenate_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 8, 8, 50)     0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 8, 8, 25)     1250        activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 8, 8, 25)     100         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 8, 8, 25)     0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 8, 8, 25)     5625        activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_25 (Concatenate)    (None, 8, 8, 75)     0           concatenate_24[0][0]             \n",
      "                                                                 conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 8, 8, 75)     300         concatenate_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 8, 8, 75)     0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 8, 8, 25)     1875        activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 8, 8, 25)     100         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 8, 8, 25)     0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 8, 8, 25)     5625        activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_26 (Concatenate)    (None, 8, 8, 100)    0           concatenate_25[0][0]             \n",
      "                                                                 conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 8, 8, 100)    400         concatenate_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 8, 8, 100)    0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 8, 8, 25)     2500        activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 8, 8, 25)     100         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 8, 8, 25)     0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 8, 8, 25)     5625        activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_27 (Concatenate)    (None, 8, 8, 125)    0           concatenate_26[0][0]             \n",
      "                                                                 conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 8, 8, 125)    500         concatenate_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 8, 8, 125)    0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 8, 8, 25)     3125        activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 8, 8, 25)     100         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 8, 8, 25)     0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 8, 8, 25)     5625        activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_28 (Concatenate)    (None, 8, 8, 150)    0           concatenate_27[0][0]             \n",
      "                                                                 conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 8, 8, 150)    600         concatenate_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 8, 8, 150)    0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 8, 8, 25)     3750        activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 8, 8, 25)     100         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 8, 8, 25)     0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 8, 8, 25)     5625        activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_29 (Concatenate)    (None, 8, 8, 175)    0           concatenate_28[0][0]             \n",
      "                                                                 conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 8, 8, 175)    700         concatenate_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 8, 8, 175)    0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 8, 8, 25)     4375        activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 8, 8, 25)     100         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 8, 8, 25)     0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 8, 8, 25)     5625        activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_30 (Concatenate)    (None, 8, 8, 200)    0           concatenate_29[0][0]             \n",
      "                                                                 conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 8, 8, 200)    800         concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 8, 8, 200)    0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 8, 8, 25)     5000        activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 8, 8, 25)     100         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 8, 8, 25)     0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 8, 8, 25)     5625        activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_31 (Concatenate)    (None, 8, 8, 225)    0           concatenate_30[0][0]             \n",
      "                                                                 conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 8, 8, 225)    900         concatenate_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 8, 8, 225)    0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 8, 8, 25)     5625        activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 8, 8, 25)     100         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 8, 8, 25)     0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 8, 8, 25)     5625        activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_32 (Concatenate)    (None, 8, 8, 250)    0           concatenate_31[0][0]             \n",
      "                                                                 conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 8, 8, 250)    1000        concatenate_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 8, 8, 250)    0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 8, 8, 25)     6250        activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 8, 8, 25)     100         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 8, 8, 25)     0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 8, 8, 25)     5625        activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_33 (Concatenate)    (None, 8, 8, 275)    0           concatenate_32[0][0]             \n",
      "                                                                 conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 8, 8, 275)    1100        concatenate_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 8, 8, 275)    0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 8, 8, 25)     6875        activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 8, 8, 25)     100         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 8, 8, 25)     0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 8, 8, 25)     5625        activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_34 (Concatenate)    (None, 8, 8, 300)    0           concatenate_33[0][0]             \n",
      "                                                                 conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 8, 8, 300)    1200        concatenate_34[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 8, 8, 300)    0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 8, 8, 25)     7500        activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 8, 8, 25)     100         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 8, 8, 25)     0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 8, 8, 25)     5625        activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_35 (Concatenate)    (None, 8, 8, 325)    0           concatenate_34[0][0]             \n",
      "                                                                 conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 8, 8, 325)    1300        concatenate_35[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 8, 8, 325)    0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 8, 8, 25)     8125        activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 4, 4, 25)     0           conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 4, 4, 25)     100         average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 4, 4, 25)     0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 4, 4, 25)     625         activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 4, 4, 25)     100         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 4, 4, 25)     0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 4, 4, 25)     5625        activation_76[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_36 (Concatenate)    (None, 4, 4, 50)     0           average_pooling2d_2[0][0]        \n",
      "                                                                 conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 4, 4, 50)     200         concatenate_36[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 4, 4, 50)     0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 4, 4, 25)     1250        activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 4, 4, 25)     100         conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 4, 4, 25)     0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 4, 4, 25)     5625        activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_37 (Concatenate)    (None, 4, 4, 75)     0           concatenate_36[0][0]             \n",
      "                                                                 conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 4, 4, 75)     300         concatenate_37[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 4, 4, 75)     0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 4, 4, 25)     1875        activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 4, 4, 25)     100         conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 4, 4, 25)     0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 4, 4, 25)     5625        activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_38 (Concatenate)    (None, 4, 4, 100)    0           concatenate_37[0][0]             \n",
      "                                                                 conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 4, 4, 100)    400         concatenate_38[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 4, 4, 100)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 4, 4, 25)     2500        activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 4, 4, 25)     100         conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 4, 4, 25)     0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 4, 4, 25)     5625        activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_39 (Concatenate)    (None, 4, 4, 125)    0           concatenate_38[0][0]             \n",
      "                                                                 conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 4, 4, 125)    500         concatenate_39[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 4, 4, 125)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 4, 4, 25)     3125        activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 4, 4, 25)     100         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 4, 4, 25)     0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 4, 4, 25)     5625        activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_40 (Concatenate)    (None, 4, 4, 150)    0           concatenate_39[0][0]             \n",
      "                                                                 conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 4, 4, 150)    600         concatenate_40[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 4, 4, 150)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 4, 4, 25)     3750        activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 4, 4, 25)     100         conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 4, 4, 25)     0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 4, 4, 25)     5625        activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_41 (Concatenate)    (None, 4, 4, 175)    0           concatenate_40[0][0]             \n",
      "                                                                 conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 4, 4, 175)    700         concatenate_41[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 4, 4, 175)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 4, 4, 25)     4375        activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 4, 4, 25)     100         conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 4, 4, 25)     0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 4, 4, 25)     5625        activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_42 (Concatenate)    (None, 4, 4, 200)    0           concatenate_41[0][0]             \n",
      "                                                                 conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 4, 4, 200)    800         concatenate_42[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 4, 4, 200)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 4, 4, 25)     5000        activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 4, 4, 25)     100         conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 4, 4, 25)     0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 4, 4, 25)     5625        activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_43 (Concatenate)    (None, 4, 4, 225)    0           concatenate_42[0][0]             \n",
      "                                                                 conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 4, 4, 225)    900         concatenate_43[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 4, 4, 225)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 4, 4, 25)     5625        activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 4, 4, 25)     100         conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 4, 4, 25)     0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 4, 4, 25)     5625        activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_44 (Concatenate)    (None, 4, 4, 250)    0           concatenate_43[0][0]             \n",
      "                                                                 conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 4, 4, 250)    1000        concatenate_44[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 4, 4, 250)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 4, 4, 25)     6250        activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 4, 4, 25)     100         conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 4, 4, 25)     0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 4, 4, 25)     5625        activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_45 (Concatenate)    (None, 4, 4, 275)    0           concatenate_44[0][0]             \n",
      "                                                                 conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 4, 4, 275)    1100        concatenate_45[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 4, 4, 275)    0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 4, 4, 25)     6875        activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 4, 4, 25)     100         conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 4, 4, 25)     0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 4, 4, 25)     5625        activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_46 (Concatenate)    (None, 4, 4, 300)    0           concatenate_45[0][0]             \n",
      "                                                                 conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 4, 4, 300)    1200        concatenate_46[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 4, 4, 300)    0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 4, 4, 25)     7500        activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 4, 4, 25)     100         conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 4, 4, 25)     0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 4, 4, 25)     5625        activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_47 (Concatenate)    (None, 4, 4, 325)    0           concatenate_46[0][0]             \n",
      "                                                                 conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 4, 4, 325)    1300        concatenate_47[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 4, 4, 325)    0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 2, 2, 325)    0           activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 1300)         0           average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           13010       flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 548,704\n",
      "Trainable params: 527,818\n",
      "Non-trainable params: 20,886\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model5 = Model(inputs = [input], outputs = [output])\n",
    "model5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YcgCJpHSeUEU",
    "outputId": "b8027c91-5079-4f1e-a0d5-19dbbfbbcb14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "355\n"
     ]
    }
   ],
   "source": [
    "print(len(model5.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ephpZeGseUAf",
    "outputId": "5259bb81-8877-4d7f-ca75-d91063e93f9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "781/781 [==============================] - 160s 153ms/step - loss: 1.8645 - accuracy: 0.3217 - val_loss: 2.1654 - val_accuracy: 0.2920\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.29200, saving model to model5_weights.best.hdf5\n",
      "Epoch 2/100\n",
      "781/781 [==============================] - 118s 151ms/step - loss: 1.5126 - accuracy: 0.4451 - val_loss: 2.6054 - val_accuracy: 0.3066\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.29200 to 0.30660, saving model to model5_weights.best.hdf5\n",
      "Epoch 3/100\n",
      "781/781 [==============================] - 119s 152ms/step - loss: 1.2816 - accuracy: 0.5356 - val_loss: 1.7561 - val_accuracy: 0.5004\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.30660 to 0.50040, saving model to model5_weights.best.hdf5\n",
      "Epoch 4/100\n",
      "781/781 [==============================] - 120s 153ms/step - loss: 1.0908 - accuracy: 0.6122 - val_loss: 1.1677 - val_accuracy: 0.6171\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.50040 to 0.61710, saving model to model5_weights.best.hdf5\n",
      "Epoch 5/100\n",
      "781/781 [==============================] - 119s 153ms/step - loss: 0.9554 - accuracy: 0.6589 - val_loss: 1.0298 - val_accuracy: 0.6521\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.61710 to 0.65210, saving model to model5_weights.best.hdf5\n",
      "Epoch 6/100\n",
      "781/781 [==============================] - 120s 154ms/step - loss: 0.8619 - accuracy: 0.6957 - val_loss: 1.2446 - val_accuracy: 0.6327\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.65210\n",
      "Epoch 7/100\n",
      "781/781 [==============================] - 119s 153ms/step - loss: 0.7958 - accuracy: 0.7197 - val_loss: 0.9859 - val_accuracy: 0.6887\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.65210 to 0.68870, saving model to model5_weights.best.hdf5\n",
      "Epoch 8/100\n",
      "781/781 [==============================] - 120s 153ms/step - loss: 0.7362 - accuracy: 0.7413 - val_loss: 0.9728 - val_accuracy: 0.6962\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.68870 to 0.69620, saving model to model5_weights.best.hdf5\n",
      "Epoch 9/100\n",
      "781/781 [==============================] - 119s 153ms/step - loss: 0.6962 - accuracy: 0.7567 - val_loss: 1.1996 - val_accuracy: 0.6552\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.69620\n",
      "Epoch 10/100\n",
      "781/781 [==============================] - 120s 153ms/step - loss: 0.6580 - accuracy: 0.7704 - val_loss: 0.8988 - val_accuracy: 0.7022\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.69620 to 0.70220, saving model to model5_weights.best.hdf5\n",
      "Epoch 11/100\n",
      "781/781 [==============================] - 120s 153ms/step - loss: 0.6234 - accuracy: 0.7828 - val_loss: 0.9954 - val_accuracy: 0.7033\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.70220 to 0.70330, saving model to model5_weights.best.hdf5\n",
      "Epoch 12/100\n",
      "781/781 [==============================] - 120s 153ms/step - loss: 0.5976 - accuracy: 0.7914 - val_loss: 0.8875 - val_accuracy: 0.7239\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.70330 to 0.72390, saving model to model5_weights.best.hdf5\n",
      "Epoch 13/100\n",
      "781/781 [==============================] - 119s 153ms/step - loss: 0.5776 - accuracy: 0.8001 - val_loss: 0.8790 - val_accuracy: 0.7306\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.72390 to 0.73060, saving model to model5_weights.best.hdf5\n",
      "Epoch 14/100\n",
      "781/781 [==============================] - 120s 153ms/step - loss: 0.5595 - accuracy: 0.8053 - val_loss: 1.1846 - val_accuracy: 0.6676\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.73060\n",
      "Epoch 15/100\n",
      "781/781 [==============================] - 120s 153ms/step - loss: 0.5326 - accuracy: 0.8162 - val_loss: 0.6720 - val_accuracy: 0.7863\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.73060 to 0.78630, saving model to model5_weights.best.hdf5\n",
      "Epoch 16/100\n",
      "781/781 [==============================] - 120s 153ms/step - loss: 0.5182 - accuracy: 0.8208 - val_loss: 0.6716 - val_accuracy: 0.7794\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.78630\n",
      "Epoch 17/100\n",
      "781/781 [==============================] - 119s 153ms/step - loss: 0.5030 - accuracy: 0.8265 - val_loss: 0.9736 - val_accuracy: 0.7291\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.78630\n",
      "Epoch 18/100\n",
      "781/781 [==============================] - 120s 153ms/step - loss: 0.4860 - accuracy: 0.8317 - val_loss: 0.7766 - val_accuracy: 0.7814\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.78630\n",
      "Epoch 19/100\n",
      "781/781 [==============================] - 120s 153ms/step - loss: 0.4732 - accuracy: 0.8361 - val_loss: 1.1807 - val_accuracy: 0.6949\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.78630\n",
      "Epoch 20/100\n",
      "781/781 [==============================] - 120s 153ms/step - loss: 0.4582 - accuracy: 0.8396 - val_loss: 0.6134 - val_accuracy: 0.8037\n",
      "\n",
      "Epoch 00020: val_accuracy improved from 0.78630 to 0.80370, saving model to model5_weights.best.hdf5\n",
      "Epoch 21/100\n",
      "781/781 [==============================] - 119s 153ms/step - loss: 0.4470 - accuracy: 0.8440 - val_loss: 0.6685 - val_accuracy: 0.7864\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.80370\n",
      "Epoch 22/100\n",
      "781/781 [==============================] - 120s 153ms/step - loss: 0.4347 - accuracy: 0.8498 - val_loss: 0.5627 - val_accuracy: 0.8141\n",
      "\n",
      "Epoch 00022: val_accuracy improved from 0.80370 to 0.81410, saving model to model5_weights.best.hdf5\n",
      "Epoch 23/100\n",
      "781/781 [==============================] - 119s 153ms/step - loss: 0.4277 - accuracy: 0.8514 - val_loss: 0.6146 - val_accuracy: 0.8029\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.81410\n",
      "Epoch 24/100\n",
      "781/781 [==============================] - 119s 152ms/step - loss: 0.4198 - accuracy: 0.8548 - val_loss: 0.5680 - val_accuracy: 0.8143\n",
      "\n",
      "Epoch 00024: val_accuracy improved from 0.81410 to 0.81430, saving model to model5_weights.best.hdf5\n",
      "Epoch 25/100\n",
      "781/781 [==============================] - 120s 154ms/step - loss: 0.4065 - accuracy: 0.8597 - val_loss: 0.7392 - val_accuracy: 0.7805\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.81430\n",
      "Epoch 26/100\n",
      "781/781 [==============================] - 120s 153ms/step - loss: 0.3311 - accuracy: 0.8833 - val_loss: 0.3738 - val_accuracy: 0.8762\n",
      "\n",
      "Epoch 00026: val_accuracy improved from 0.81430 to 0.87620, saving model to model5_weights.best.hdf5\n",
      "Epoch 27/100\n",
      "781/781 [==============================] - 120s 153ms/step - loss: 0.3031 - accuracy: 0.8946 - val_loss: 0.3818 - val_accuracy: 0.8785\n",
      "\n",
      "Epoch 00027: val_accuracy improved from 0.87620 to 0.87850, saving model to model5_weights.best.hdf5\n",
      "Epoch 28/100\n",
      "781/781 [==============================] - 120s 153ms/step - loss: 0.2953 - accuracy: 0.8979 - val_loss: 0.3645 - val_accuracy: 0.8801\n",
      "\n",
      "Epoch 00028: val_accuracy improved from 0.87850 to 0.88010, saving model to model5_weights.best.hdf5\n",
      "Epoch 29/100\n",
      "781/781 [==============================] - 120s 154ms/step - loss: 0.2857 - accuracy: 0.9000 - val_loss: 0.3744 - val_accuracy: 0.8788\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.88010\n",
      "Epoch 30/100\n",
      "781/781 [==============================] - 120s 154ms/step - loss: 0.2830 - accuracy: 0.9021 - val_loss: 0.3479 - val_accuracy: 0.8904\n",
      "\n",
      "Epoch 00030: val_accuracy improved from 0.88010 to 0.89040, saving model to model5_weights.best.hdf5\n",
      "Epoch 31/100\n",
      "781/781 [==============================] - 120s 153ms/step - loss: 0.2742 - accuracy: 0.9052 - val_loss: 0.3228 - val_accuracy: 0.8932\n",
      "\n",
      "Epoch 00031: val_accuracy improved from 0.89040 to 0.89320, saving model to model5_weights.best.hdf5\n",
      "Epoch 32/100\n",
      "781/781 [==============================] - 121s 154ms/step - loss: 0.2747 - accuracy: 0.9045 - val_loss: 0.3600 - val_accuracy: 0.8826\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.89320\n",
      "Epoch 33/100\n",
      "781/781 [==============================] - 120s 154ms/step - loss: 0.2678 - accuracy: 0.9067 - val_loss: 0.3407 - val_accuracy: 0.8885\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.89320\n",
      "Epoch 34/100\n",
      "781/781 [==============================] - 120s 154ms/step - loss: 0.2657 - accuracy: 0.9079 - val_loss: 0.3401 - val_accuracy: 0.8903\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.89320\n",
      "Epoch 35/100\n",
      "781/781 [==============================] - 122s 156ms/step - loss: 0.2603 - accuracy: 0.9085 - val_loss: 0.3519 - val_accuracy: 0.8881\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.89320\n",
      "Epoch 36/100\n",
      "781/781 [==============================] - 122s 156ms/step - loss: 0.2561 - accuracy: 0.9113 - val_loss: 0.3397 - val_accuracy: 0.8891\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.89320\n",
      "Epoch 37/100\n",
      "781/781 [==============================] - 122s 156ms/step - loss: 0.2539 - accuracy: 0.9115 - val_loss: 0.3564 - val_accuracy: 0.8879\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.89320\n",
      "Epoch 38/100\n",
      "781/781 [==============================] - 121s 155ms/step - loss: 0.2542 - accuracy: 0.9126 - val_loss: 0.3587 - val_accuracy: 0.8870\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.89320\n",
      "Epoch 39/100\n",
      "781/781 [==============================] - 121s 155ms/step - loss: 0.2510 - accuracy: 0.9121 - val_loss: 0.3576 - val_accuracy: 0.8875\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.89320\n",
      "Epoch 40/100\n",
      "781/781 [==============================] - 121s 155ms/step - loss: 0.2467 - accuracy: 0.9143 - val_loss: 0.3505 - val_accuracy: 0.8896\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.89320\n",
      "Epoch 41/100\n",
      "781/781 [==============================] - 121s 155ms/step - loss: 0.2480 - accuracy: 0.9129 - val_loss: 0.3604 - val_accuracy: 0.8866\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.89320\n",
      "Epoch 42/100\n",
      "781/781 [==============================] - 121s 155ms/step - loss: 0.2457 - accuracy: 0.9144 - val_loss: 0.3695 - val_accuracy: 0.8819\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.89320\n",
      "Epoch 43/100\n",
      "781/781 [==============================] - 121s 155ms/step - loss: 0.2406 - accuracy: 0.9162 - val_loss: 0.3325 - val_accuracy: 0.8966\n",
      "\n",
      "Epoch 00043: val_accuracy improved from 0.89320 to 0.89660, saving model to model5_weights.best.hdf5\n",
      "Epoch 44/100\n",
      "781/781 [==============================] - 121s 155ms/step - loss: 0.2363 - accuracy: 0.9167 - val_loss: 0.3364 - val_accuracy: 0.8912\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.89660\n",
      "Epoch 45/100\n",
      "781/781 [==============================] - 121s 155ms/step - loss: 0.2369 - accuracy: 0.9161 - val_loss: 0.3447 - val_accuracy: 0.8910\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.89660\n",
      "Epoch 46/100\n",
      "781/781 [==============================] - 121s 155ms/step - loss: 0.2347 - accuracy: 0.9184 - val_loss: 0.3308 - val_accuracy: 0.8934\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.89660\n",
      "Epoch 47/100\n",
      "781/781 [==============================] - 121s 155ms/step - loss: 0.2294 - accuracy: 0.9199 - val_loss: 0.3310 - val_accuracy: 0.8966\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.89660\n",
      "Epoch 48/100\n",
      "781/781 [==============================] - 122s 156ms/step - loss: 0.2279 - accuracy: 0.9204 - val_loss: 0.3455 - val_accuracy: 0.8918\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.89660\n",
      "Epoch 49/100\n",
      "781/781 [==============================] - 122s 156ms/step - loss: 0.2311 - accuracy: 0.9192 - val_loss: 0.3227 - val_accuracy: 0.8988\n",
      "\n",
      "Epoch 00049: val_accuracy improved from 0.89660 to 0.89880, saving model to model5_weights.best.hdf5\n",
      "Epoch 50/100\n",
      "781/781 [==============================] - 121s 155ms/step - loss: 0.2281 - accuracy: 0.9198 - val_loss: 0.3356 - val_accuracy: 0.8942\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.89880\n",
      "Epoch 51/100\n",
      "781/781 [==============================] - 121s 155ms/step - loss: 0.2194 - accuracy: 0.9224 - val_loss: 0.3308 - val_accuracy: 0.8966\n",
      "\n",
      "Epoch 00051: val_accuracy did not improve from 0.89880\n",
      "Epoch 52/100\n",
      "781/781 [==============================] - 121s 155ms/step - loss: 0.2182 - accuracy: 0.9234 - val_loss: 0.3265 - val_accuracy: 0.8978\n",
      "\n",
      "Epoch 00052: val_accuracy did not improve from 0.89880\n",
      "Epoch 53/100\n",
      "781/781 [==============================] - 121s 155ms/step - loss: 0.2164 - accuracy: 0.9233 - val_loss: 0.3286 - val_accuracy: 0.8979\n",
      "\n",
      "Epoch 00053: val_accuracy did not improve from 0.89880\n",
      "Epoch 54/100\n",
      "781/781 [==============================] - 121s 154ms/step - loss: 0.2166 - accuracy: 0.9241 - val_loss: 0.3309 - val_accuracy: 0.8973\n",
      "\n",
      "Epoch 00054: val_accuracy did not improve from 0.89880\n",
      "Epoch 55/100\n",
      "781/781 [==============================] - 121s 155ms/step - loss: 0.2165 - accuracy: 0.9248 - val_loss: 0.3279 - val_accuracy: 0.8978\n",
      "\n",
      "Epoch 00055: val_accuracy did not improve from 0.89880\n",
      "Epoch 56/100\n",
      "781/781 [==============================] - 121s 155ms/step - loss: 0.2141 - accuracy: 0.9245 - val_loss: 0.3245 - val_accuracy: 0.8983\n",
      "\n",
      "Epoch 00056: val_accuracy did not improve from 0.89880\n",
      "Epoch 57/100\n",
      "781/781 [==============================] - 121s 155ms/step - loss: 0.2153 - accuracy: 0.9244 - val_loss: 0.3288 - val_accuracy: 0.8982\n",
      "\n",
      "Epoch 00057: val_accuracy did not improve from 0.89880\n",
      "Epoch 58/100\n",
      "781/781 [==============================] - 121s 155ms/step - loss: 0.2150 - accuracy: 0.9241 - val_loss: 0.3253 - val_accuracy: 0.8985\n",
      "\n",
      "Epoch 00058: val_accuracy did not improve from 0.89880\n",
      "Epoch 59/100\n",
      "781/781 [==============================] - 121s 155ms/step - loss: 0.2099 - accuracy: 0.9261 - val_loss: 0.3230 - val_accuracy: 0.8998\n",
      "\n",
      "Epoch 00059: val_accuracy improved from 0.89880 to 0.89980, saving model to model5_weights.best.hdf5\n",
      "Epoch 60/100\n",
      "781/781 [==============================] - 121s 155ms/step - loss: 0.2105 - accuracy: 0.9263 - val_loss: 0.3285 - val_accuracy: 0.8978\n",
      "\n",
      "Epoch 00060: val_accuracy did not improve from 0.89980\n",
      "Epoch 61/100\n",
      "781/781 [==============================] - 121s 155ms/step - loss: 0.2122 - accuracy: 0.9259 - val_loss: 0.3254 - val_accuracy: 0.8990\n",
      "\n",
      "Epoch 00061: val_accuracy did not improve from 0.89980\n",
      "Epoch 62/100\n",
      "781/781 [==============================] - 121s 155ms/step - loss: 0.2066 - accuracy: 0.9275 - val_loss: 0.3238 - val_accuracy: 0.8991\n",
      "\n",
      "Epoch 00062: val_accuracy did not improve from 0.89980\n",
      "Epoch 63/100\n",
      "781/781 [==============================] - 121s 155ms/step - loss: 0.2088 - accuracy: 0.9268 - val_loss: 0.3285 - val_accuracy: 0.8968\n",
      "\n",
      "Epoch 00063: val_accuracy did not improve from 0.89980\n",
      "Epoch 64/100\n",
      "781/781 [==============================] - 122s 156ms/step - loss: 0.2140 - accuracy: 0.9231 - val_loss: 0.3257 - val_accuracy: 0.8979\n",
      "\n",
      "Epoch 00064: val_accuracy did not improve from 0.89980\n",
      "Epoch 65/100\n",
      "781/781 [==============================] - 121s 155ms/step - loss: 0.2067 - accuracy: 0.9280 - val_loss: 0.3275 - val_accuracy: 0.8980\n",
      "\n",
      "Epoch 00065: val_accuracy did not improve from 0.89980\n",
      "Epoch 66/100\n",
      "781/781 [==============================] - 121s 155ms/step - loss: 0.2089 - accuracy: 0.9256 - val_loss: 0.3267 - val_accuracy: 0.8980\n",
      "\n",
      "Epoch 00066: val_accuracy did not improve from 0.89980\n",
      "Epoch 67/100\n",
      "781/781 [==============================] - 121s 155ms/step - loss: 0.2127 - accuracy: 0.9258 - val_loss: 0.3208 - val_accuracy: 0.8991\n",
      "\n",
      "Epoch 00067: val_accuracy did not improve from 0.89980\n",
      "Epoch 68/100\n",
      "781/781 [==============================] - 121s 155ms/step - loss: 0.2119 - accuracy: 0.9255 - val_loss: 0.3262 - val_accuracy: 0.8983\n",
      "\n",
      "Epoch 00068: val_accuracy did not improve from 0.89980\n",
      "Epoch 69/100\n",
      "781/781 [==============================] - 121s 155ms/step - loss: 0.2091 - accuracy: 0.9264 - val_loss: 0.3237 - val_accuracy: 0.8991\n",
      "\n",
      "Epoch 00069: val_accuracy did not improve from 0.89980\n",
      "Epoch 70/100\n",
      "781/781 [==============================] - 121s 155ms/step - loss: 0.2090 - accuracy: 0.9274 - val_loss: 0.3212 - val_accuracy: 0.9015\n",
      "\n",
      "Epoch 00070: val_accuracy improved from 0.89980 to 0.90150, saving model to model5_weights.best.hdf5\n",
      "Epoch 71/100\n",
      "781/781 [==============================] - 121s 155ms/step - loss: 0.2102 - accuracy: 0.9264 - val_loss: 0.3249 - val_accuracy: 0.8994\n",
      "\n",
      "Epoch 00071: val_accuracy did not improve from 0.90150\n",
      "Epoch 72/100\n",
      "781/781 [==============================] - 121s 154ms/step - loss: 0.2115 - accuracy: 0.9262 - val_loss: 0.3298 - val_accuracy: 0.8973\n",
      "\n",
      "Epoch 00072: val_accuracy did not improve from 0.90150\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f80f632c350>"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model5.fit(aug.flow(X_train,y_train,batch_size=batch_size),epochs=nb_epoch,batch_size=batch_size,verbose=1,\n",
    "           steps_per_epoch=(len(X_train)//batch_size),\n",
    "           callbacks=[reduce_lr,lr_scheduler,csv_logger,early_stop,model_checkpoint],\n",
    "           validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "kADL0zj2yzJJ",
    "outputId": "3ad81a77-a24f-40fa-f4fc-151be8763940"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>loss</th>\n",
       "      <th>lr</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.321692</td>\n",
       "      <td>1.864464</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.2920</td>\n",
       "      <td>2.165388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.445070</td>\n",
       "      <td>1.512568</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.3066</td>\n",
       "      <td>2.605386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.535646</td>\n",
       "      <td>1.281641</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.5004</td>\n",
       "      <td>1.756118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.612224</td>\n",
       "      <td>1.090826</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.6171</td>\n",
       "      <td>1.167669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.658863</td>\n",
       "      <td>0.955366</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.6521</td>\n",
       "      <td>1.029768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>67</td>\n",
       "      <td>0.925485</td>\n",
       "      <td>0.211873</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.8983</td>\n",
       "      <td>0.326231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>68</td>\n",
       "      <td>0.926426</td>\n",
       "      <td>0.209126</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.8991</td>\n",
       "      <td>0.323680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>69</td>\n",
       "      <td>0.927447</td>\n",
       "      <td>0.209021</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.9015</td>\n",
       "      <td>0.321206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>70</td>\n",
       "      <td>0.926446</td>\n",
       "      <td>0.210156</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.8994</td>\n",
       "      <td>0.324877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>71</td>\n",
       "      <td>0.926206</td>\n",
       "      <td>0.211468</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.8973</td>\n",
       "      <td>0.329835</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch  accuracy      loss      lr  val_accuracy  val_loss\n",
       "0       0  0.321692  1.864464  0.0100        0.2920  2.165388\n",
       "1       1  0.445070  1.512568  0.0100        0.3066  2.605386\n",
       "2       2  0.535646  1.281641  0.0100        0.5004  1.756118\n",
       "3       3  0.612224  1.090826  0.0100        0.6171  1.167669\n",
       "4       4  0.658863  0.955366  0.0100        0.6521  1.029768\n",
       "..    ...       ...       ...     ...           ...       ...\n",
       "67     67  0.925485  0.211873  0.0001        0.8983  0.326231\n",
       "68     68  0.926426  0.209126  0.0001        0.8991  0.323680\n",
       "69     69  0.927447  0.209021  0.0001        0.9015  0.321206\n",
       "70     70  0.926446  0.210156  0.0001        0.8994  0.324877\n",
       "71     71  0.926206  0.211468  0.0001        0.8973  0.329835\n",
       "\n",
       "[72 rows x 6 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "training_log = pd.read_csv('/content/training.log')\n",
    "training_log.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jyjXikkiyzGM",
    "outputId": "a2cfdf5c-e5b8-4051-a5d1-f868981de038"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created and weights loaded from file\n"
     ]
    }
   ],
   "source": [
    "model5.load_weights('/content/model5_weights.best.hdf5')\n",
    "model5.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "print(\"Model created and weights loaded from file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fEMtpNatyzDM",
    "outputId": "d2ce0e97-c9f3-4a7a-bd39-77b401fae9a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss =  0.32120639085769653\n",
      "Test accuracy =  0.9014999866485596\n"
     ]
    }
   ],
   "source": [
    "score = model5.evaluate(X_test,y_test,verbose=0)\n",
    "print(\"Test loss = \",score[0])\n",
    "print(\"Test accuracy = \",score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OUZaKCCe1Yi1"
   },
   "source": [
    "### 2.5 Plotting loss and accuracy of Model 5 above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "VoMsej6Nyy84",
    "outputId": "39820fe4-4b9c-4e1f-800c-cdabe37d3aa9"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#https://machinelearningmastery.com/display-deep-learning-model-training-history-in-keras/\n",
    "plt.plot(training_log['accuracy'])\n",
    "plt.plot(training_log['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','test'],loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "EePumR7uyy6Z",
    "outputId": "a7680544-faea-4ae4-d679-69dbc3b1e55d"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#https://machinelearningmastery.com/display-deep-learning-model-training-history-in-keras/\n",
    "plt.plot(training_log['loss'])\n",
    "plt.plot(training_log['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['train','test'],loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iT4Q8IEl1oVc"
   },
   "source": [
    "## 3. Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lfO5o9kFyy24",
    "outputId": "b3540ad3-8644-442b-e380-3d572c188545"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------+-------------+---------------+\n",
      "| Growth Rate | Compression | # of Blocks | Test Accuracy |\n",
      "+-------------+-------------+-------------+---------------+\n",
      "|      36     |     0.7     |      12     |     90.149    |\n",
      "+-------------+-------------+-------------+---------------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "x = PrettyTable()\n",
    "x.field_names = ['Growth Rate','Compression','# of Blocks','Test Accuracy']\n",
    "x.add_row([36,0.7,12,90.149])\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q78J2HCfeTRX"
   },
   "source": [
    "__*Summary:*__\n",
    "\n",
    "I have used Keras callbacks to adjust the learning rate as per the performance of the model(ReduceLRonPlateau,LearningRate Sceduler).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LpBGMqq7eTO-"
   },
   "source": [
    "**Additional links and resuorces:**\n",
    "\n",
    "1.\t2016 DenseNet paper summary: https://www.youtube.com/watch?v=hSC_0S8Zf9s\n",
    "2. \tSeparable Depth wise convolutions: https://towardsdatascience.com/a-basic-introduction-to-separable-convolutions-b99ec3102728\n",
    "3. Review DenseNet image classification: https://towardsdatascience.com/review-densenet-image-classification-b6631a8ef803"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8KS-J_lreTMX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HeRovVjo_9W3"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DenseNet_CIFAR_Final.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
