{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "knRpYoAnwr1c"
   },
   "source": [
    "# Implement DenseNet on CIFAR-10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index\n",
    "\n",
    "1. Assignment instructions\n",
    "\n",
    "\n",
    "\n",
    "2. Assignment\n",
    " - 2.1 Defining Dense Block, Transition Block and Output Block\n",
    " - 2.2 Using Data Augmentation for training the DenseNet\n",
    " - 2.3 Using LearningRateScheduler, ReduceLRonPlateau,CSVLogger in callbacks\n",
    " - 2.4 Growth rate(num_filter)=24, compression = 0.5, number of blocks = 12\n",
    " - 2.5 Growth rate(num_filter)=32, compression = 0.7, Number of blocks = 12\n",
    " - 2.6 Growth Rate(num_filter) = 36, compression = 0.7, Number of blocks = 12\n",
    " - 2.7 Plotting loss and accuracy of Model 5 above\n",
    "\n",
    "\n",
    "3. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dVbwx0fewziM"
   },
   "source": [
    "## 1. Assignment instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ucjyE-mnxAVC"
   },
   "source": [
    "1.  Please visit this link to access the state-of-art DenseNet code for reference - DenseNet - cifar10 notebook link\n",
    "2.  You need to create a copy of this and \"retrain\" this model to achieve 90+ test accuracy. \n",
    "3.  You cannot use DropOut layers.\n",
    "4.  You MUST use Image Augmentation Techniques.\n",
    "5.  You cannot use an already trained model as a beginning points, you have to initilize as your own\n",
    "6.  You cannot run the program for more than 300 Epochs, and it should be clear from your log, that you have only used 300 Epochs\n",
    "7.  You cannot use test images for training the model.\n",
    "8.  You cannot change the general architecture of DenseNet (which means you must use Dense Block, Transition and Output blocks as mentioned in the code)\n",
    "9.  You are free to change Convolution types (e.g. from 3x3 normal convolution to Depthwise Separable, etc)\n",
    "10. You cannot have more than 1 Million parameters in total\n",
    "11. You are free to move the code from Keras to Tensorflow, Pytorch, MXNET etc. \n",
    "12. You can use any optimization algorithm you need. \n",
    "13. You can checkpoint your model and retrain the model from that checkpoint so that no need of training the model from first if you lost at any epoch while training. You can directly load that model and Train from that epoch. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ALdcoVTVy9hd"
   },
   "source": [
    "## 2. Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gbII1-uhfMG0"
   },
   "outputs": [],
   "source": [
    "# import keras\n",
    "# from keras.datasets import cifar10\n",
    "# from keras.models import Model, Sequential\n",
    "# from keras.layers import Dense, Dropout, Flatten, Input, AveragePooling2D, merge, Activation\n",
    "# from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "# from keras.layers import Concatenate\n",
    "# from keras.optimizers import Adam\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation, Flatten\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vZjxA5HWf5RN"
   },
   "outputs": [],
   "source": [
    "# this part will prevent tensorflow to allocate all the avaliable GPU Memory\n",
    "# backend\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b2xm8NSqf5L-",
    "outputId": "d21e6cad-55d4-4fc5-9b80-7f59746d8352"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Load CIFAR10 Data\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "img_height, img_width, channel = X_train.shape[1],X_train.shape[2],X_train.shape[3]\n",
    "\n",
    "#scale the data (images) to [0,1] range\n",
    "X_train = X_train.astype(\"float32\")/255\n",
    "X_test = X_test.astype(\"float32\")/255\n",
    "\n",
    "# convert to one hot encoding\n",
    "num_classes = 10 \n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QypLwCjlf5JX",
    "outputId": "e94fe5fc-a293-45b3-c3d0-ddc1e0eba5cc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FFY6o1C4f5Gn",
    "outputId": "5f313e82-13c0-4d43-b557-b35baac9ffd4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 32, 32, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g-HDwYenzMOY"
   },
   "source": [
    "### 2.1 Defining Dense Block, Transition Block and Output Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ttgY82f1f5D_"
   },
   "outputs": [],
   "source": [
    "# Dense Block\n",
    "def denseblock(input, num_filter = 12, dropout_rate = 0.2):\n",
    "    global compression\n",
    "    temp = input\n",
    "    for _ in range(l): \n",
    "        BatchNorm = layers.BatchNormalization()(temp)\n",
    "        relu = layers.Activation('relu')(BatchNorm)\n",
    "        Conv2D_1_1 = layers.Conv2D(int(num_filter*compression), (1,1),use_bias=False,padding='same')(relu)\n",
    "        BatchNorm1 = layers.BatchNormalization()(Conv2D_1_1)\n",
    "        relu1 = layers.Activation('relu')(BatchNorm1)\n",
    "        Conv2D_3_3 = layers.Conv2D(int(num_filter*compression), (3,3), use_bias=False ,padding='same')(relu1)\n",
    "        if dropout_rate>0:\n",
    "            Conv2D_3_3 = layers.Dropout(dropout_rate)(Conv2D_3_3)\n",
    "        concat = layers.Concatenate(axis=-1)([temp,Conv2D_3_3])\n",
    "        \n",
    "        temp = concat\n",
    "        \n",
    "    return temp\n",
    "\n",
    "## transition Block\n",
    "def transition(input, num_filter = 12, dropout_rate = 0.2):\n",
    "    global compression\n",
    "    BatchNorm = layers.BatchNormalization()(input)\n",
    "    relu = layers.Activation('relu')(BatchNorm)\n",
    "    Conv2D_BottleNeck = layers.Conv2D(int(num_filter*compression), (1,1), use_bias=False ,padding='same')(relu)\n",
    "    if dropout_rate>0:\n",
    "         Conv2D_BottleNeck = layers.Dropout(dropout_rate)(Conv2D_BottleNeck)\n",
    "    avg = layers.AveragePooling2D(pool_size=(2,2))(Conv2D_BottleNeck)\n",
    "    return avg\n",
    "\n",
    "#output layer\n",
    "def output_layer(input):\n",
    "    global compression\n",
    "    BatchNorm = layers.BatchNormalization()(input)\n",
    "    relu = layers.Activation('relu')(BatchNorm)\n",
    "    AvgPooling = layers.AveragePooling2D(pool_size=(2,2))(relu)\n",
    "    flat = layers.Flatten()(AvgPooling)\n",
    "    output = layers.Dense(num_classes, activation='softmax')(flat)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wFJlaX9I2jVk"
   },
   "source": [
    "### 2.2 Using Data Augmentation for training the DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nY4LGoBX03jm"
   },
   "outputs": [],
   "source": [
    "#https://www.pyimagesearch.com/2018/12/24/how-to-use-keras-fit-and-fit_generator-a-hands-on-tutorial/\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "#creating a training image generator for data augmentation\n",
    "aug = ImageDataGenerator(rotation_range=0.20,width_shift_range=0.20,height_shift_range=0.15,shear_range=0.15,\n",
    "                         zoom_range=0.30,horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0kB5h_nA1NuD"
   },
   "source": [
    "### 2.3 Using LearningRateScheduler, ReduceLRonPlateau,CSVLogger in callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e-wqw66X02v2"
   },
   "outputs": [],
   "source": [
    "#https://keras.io/api/callbacks/reduce_lr_on_plateau/\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BKwSPFlx02s7"
   },
   "outputs": [],
   "source": [
    "#https://keras.io/api/callbacks/learning_rate_scheduler/\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "lr_list = [0.01,0.001,0.0001]\n",
    "def scheduler(epoch,lr):\n",
    "  if epoch<25:\n",
    "    return lr_list[0]\n",
    "  if epoch>=25 and epoch<50:\n",
    "    return lr_list[1]\n",
    "  else:\n",
    "    return lr_list[2]\n",
    "\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "umUN12qx02qK"
   },
   "outputs": [],
   "source": [
    "#https://keras.io/api/callbacks/csv_logger/\n",
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "\n",
    "csv_logger = CSVLogger('training.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7RuU_YEI9Cc7"
   },
   "outputs": [],
   "source": [
    "#https://keras.io/api/callbacks/early_stopping/\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stop = EarlyStopping(monitor='loss',patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8iSfyzFK_AAF"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "#https://machinelearningmastery.com/check-point-deep-learning-models-keras/\n",
    "filepath=\"weights.best.hdf5\"\n",
    "model_checkpoint = ModelCheckpoint(filepath,monitor='val_accuracy',save_best_only=True,verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q9qymhpM0o8h"
   },
   "source": [
    "### 2.4 Growth rate(num_filter)=24, compression = 0.5, number of blocks = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZcKil41H02nN"
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "nb_epoch = 100\n",
    "l = 12\n",
    "num_filter = 24\n",
    "compression = 0.5\n",
    "dropout_rate = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I8bEiEdp02lE"
   },
   "outputs": [],
   "source": [
    "input = layers.Input(shape=(img_height, img_width, channel,))\n",
    "First_Conv2D = layers.Conv2D(num_filter, (3,3), use_bias=False ,padding='same')(input)\n",
    "\n",
    "First_Block = denseblock(First_Conv2D, num_filter, dropout_rate)\n",
    "First_Transition = transition(First_Block, num_filter, dropout_rate)\n",
    "\n",
    "Second_Block = denseblock(First_Transition, num_filter, dropout_rate)\n",
    "Second_Transition = transition(Second_Block, num_filter, dropout_rate)\n",
    "\n",
    "Third_Block = denseblock(Second_Transition, num_filter, dropout_rate)\n",
    "Third_Transition = transition(Third_Block, num_filter, dropout_rate)\n",
    "\n",
    "Last_Block = denseblock(Third_Transition,  num_filter, dropout_rate)\n",
    "output = output_layer(Last_Block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nKev8hJd02hs",
    "outputId": "9af5ef7c-1512-448f-ab94-3533df2984b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 32, 32, 24)   648         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 32, 32, 24)   96          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 32, 32, 24)   0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 32, 32, 12)   288         activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 32, 12)   48          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 32, 32, 12)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 12)   1296        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 32, 32, 12)   0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 32, 32, 36)   0           conv2d[0][0]                     \n",
      "                                                                 dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 36)   144         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 32, 32, 36)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 32, 12)   432         activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 32, 12)   48          conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 32, 32, 12)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 32, 32, 12)   1296        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 32, 32, 12)   0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 32, 32, 48)   0           concatenate[0][0]                \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 32, 32, 48)   192         concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 32, 32, 48)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 32, 32, 12)   576         activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32, 32, 12)   48          conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 32, 32, 12)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 12)   1296        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 32, 32, 12)   0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 32, 32, 60)   0           concatenate_1[0][0]              \n",
      "                                                                 dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 32, 32, 60)   240         concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 32, 32, 60)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 12)   720         activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 32, 32, 12)   48          conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 32, 32, 12)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 12)   1296        activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 32, 32, 12)   0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 32, 32, 72)   0           concatenate_2[0][0]              \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 32, 72)   288         concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 32, 32, 72)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 12)   864         activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 32, 32, 12)   48          conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 32, 32, 12)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 32, 32, 12)   1296        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 32, 32, 12)   0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 32, 32, 84)   0           concatenate_3[0][0]              \n",
      "                                                                 dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 32, 32, 84)   336         concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 32, 32, 84)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 32, 32, 12)   1008        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 32, 32, 12)   48          conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 32, 32, 12)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 32, 32, 12)   1296        activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 32, 32, 12)   0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 32, 32, 96)   0           concatenate_4[0][0]              \n",
      "                                                                 dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 32, 32, 96)   384         concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 32, 32, 96)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 32, 32, 12)   1152        activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 32, 32, 12)   48          conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 32, 32, 12)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 32, 32, 12)   1296        activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 32, 32, 12)   0           conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 32, 32, 108)  0           concatenate_5[0][0]              \n",
      "                                                                 dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 32, 32, 108)  432         concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 32, 32, 108)  0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 32, 32, 12)   1296        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 32, 32, 12)   48          conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 32, 32, 12)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 32, 32, 12)   1296        activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 32, 32, 12)   0           conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 32, 32, 120)  0           concatenate_6[0][0]              \n",
      "                                                                 dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 32, 32, 120)  480         concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 32, 32, 120)  0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 32, 32, 12)   1440        activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 32, 32, 12)   48          conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 32, 32, 12)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 32, 32, 12)   1296        activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 32, 32, 12)   0           conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 32, 32, 132)  0           concatenate_7[0][0]              \n",
      "                                                                 dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 32, 32, 132)  528         concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 32, 32, 132)  0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 32, 32, 12)   1584        activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 32, 32, 12)   48          conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 32, 32, 12)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 32, 32, 12)   1296        activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 32, 32, 12)   0           conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 32, 32, 144)  0           concatenate_8[0][0]              \n",
      "                                                                 dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 32, 32, 144)  576         concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 32, 32, 144)  0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 32, 32, 12)   1728        activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 32, 32, 12)   48          conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 32, 32, 12)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 32, 32, 12)   1296        activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 32, 32, 12)   0           conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 32, 32, 156)  0           concatenate_9[0][0]              \n",
      "                                                                 dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 32, 32, 156)  624         concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 32, 32, 156)  0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 32, 32, 12)   1872        activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 32, 32, 12)   48          conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 32, 32, 12)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 32, 32, 12)   1296        activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 32, 32, 12)   0           conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 32, 32, 168)  0           concatenate_10[0][0]             \n",
      "                                                                 dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 32, 32, 168)  672         concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 32, 32, 168)  0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 32, 32, 12)   2016        activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 32, 32, 12)   0           conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 16, 16, 12)   0           dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 16, 16, 12)   48          average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 16, 16, 12)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 16, 16, 12)   144         activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 16, 16, 12)   48          conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 16, 16, 12)   0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 16, 16, 12)   1296        activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 16, 16, 12)   0           conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 16, 16, 24)   0           average_pooling2d[0][0]          \n",
      "                                                                 dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 16, 16, 24)   96          concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 16, 16, 24)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 16, 16, 12)   288         activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 16, 16, 12)   48          conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 16, 16, 12)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 16, 16, 12)   1296        activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 16, 16, 12)   0           conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 16, 16, 36)   0           concatenate_12[0][0]             \n",
      "                                                                 dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 16, 16, 36)   144         concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 16, 16, 36)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 16, 16, 12)   432         activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 16, 16, 12)   48          conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 16, 16, 12)   0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 16, 16, 12)   1296        activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 16, 16, 12)   0           conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 16, 16, 48)   0           concatenate_13[0][0]             \n",
      "                                                                 dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 16, 16, 48)   192         concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 16, 16, 48)   0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 16, 16, 12)   576         activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 16, 16, 12)   48          conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 16, 16, 12)   0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 16, 16, 12)   1296        activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 16, 16, 12)   0           conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 16, 16, 60)   0           concatenate_14[0][0]             \n",
      "                                                                 dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 16, 16, 60)   240         concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 16, 16, 60)   0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 16, 16, 12)   720         activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 16, 16, 12)   48          conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 16, 16, 12)   0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 16, 16, 12)   1296        activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 16, 16, 12)   0           conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 16, 16, 72)   0           concatenate_15[0][0]             \n",
      "                                                                 dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 16, 16, 72)   288         concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 16, 16, 72)   0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 16, 16, 12)   864         activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 16, 16, 12)   48          conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 16, 16, 12)   0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 16, 16, 12)   1296        activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 16, 16, 12)   0           conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, 16, 16, 84)   0           concatenate_16[0][0]             \n",
      "                                                                 dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 16, 16, 84)   336         concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 16, 16, 84)   0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 16, 16, 12)   1008        activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 16, 16, 12)   48          conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 16, 16, 12)   0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 16, 16, 12)   1296        activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 16, 16, 12)   0           conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, 16, 16, 96)   0           concatenate_17[0][0]             \n",
      "                                                                 dropout_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 16, 16, 96)   384         concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 16, 16, 96)   0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 16, 16, 12)   1152        activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 16, 16, 12)   48          conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 16, 16, 12)   0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 16, 16, 12)   1296        activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 16, 16, 12)   0           conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, 16, 16, 108)  0           concatenate_18[0][0]             \n",
      "                                                                 dropout_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 16, 16, 108)  432         concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 16, 16, 108)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 16, 16, 12)   1296        activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 16, 16, 12)   48          conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 16, 16, 12)   0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 16, 16, 12)   1296        activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 16, 16, 12)   0           conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_20 (Concatenate)    (None, 16, 16, 120)  0           concatenate_19[0][0]             \n",
      "                                                                 dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 16, 16, 120)  480         concatenate_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 16, 16, 120)  0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 16, 16, 12)   1440        activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 16, 16, 12)   48          conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 16, 16, 12)   0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 16, 16, 12)   1296        activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 16, 16, 12)   0           conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_21 (Concatenate)    (None, 16, 16, 132)  0           concatenate_20[0][0]             \n",
      "                                                                 dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 16, 16, 132)  528         concatenate_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 16, 16, 132)  0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 16, 16, 12)   1584        activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 16, 16, 12)   48          conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 16, 16, 12)   0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 16, 16, 12)   1296        activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 16, 16, 12)   0           conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_22 (Concatenate)    (None, 16, 16, 144)  0           concatenate_21[0][0]             \n",
      "                                                                 dropout_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 16, 16, 144)  576         concatenate_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 16, 16, 144)  0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 16, 16, 12)   1728        activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 16, 16, 12)   48          conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 16, 16, 12)   0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 16, 16, 12)   1296        activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 16, 16, 12)   0           conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_23 (Concatenate)    (None, 16, 16, 156)  0           concatenate_22[0][0]             \n",
      "                                                                 dropout_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 16, 16, 156)  624         concatenate_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 16, 16, 156)  0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 16, 16, 12)   1872        activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, 16, 16, 12)   0           conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 8, 8, 12)     0           dropout_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 8, 8, 12)     48          average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 8, 8, 12)     0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 8, 8, 12)     144         activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 8, 8, 12)     48          conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 8, 8, 12)     0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 8, 8, 12)     1296        activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)            (None, 8, 8, 12)     0           conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_24 (Concatenate)    (None, 8, 8, 24)     0           average_pooling2d_1[0][0]        \n",
      "                                                                 dropout_26[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 8, 8, 24)     96          concatenate_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 8, 8, 24)     0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 8, 8, 12)     288         activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 8, 8, 12)     48          conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 8, 8, 12)     0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 8, 8, 12)     1296        activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)            (None, 8, 8, 12)     0           conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_25 (Concatenate)    (None, 8, 8, 36)     0           concatenate_24[0][0]             \n",
      "                                                                 dropout_27[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 8, 8, 36)     144         concatenate_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 8, 8, 36)     0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 8, 8, 12)     432         activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 8, 8, 12)     48          conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 8, 8, 12)     0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 8, 8, 12)     1296        activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_28 (Dropout)            (None, 8, 8, 12)     0           conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_26 (Concatenate)    (None, 8, 8, 48)     0           concatenate_25[0][0]             \n",
      "                                                                 dropout_28[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 8, 8, 48)     192         concatenate_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 8, 8, 48)     0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 8, 8, 12)     576         activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 8, 8, 12)     48          conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 8, 8, 12)     0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 8, 8, 12)     1296        activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_29 (Dropout)            (None, 8, 8, 12)     0           conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_27 (Concatenate)    (None, 8, 8, 60)     0           concatenate_26[0][0]             \n",
      "                                                                 dropout_29[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 8, 8, 60)     240         concatenate_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 8, 8, 60)     0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 8, 8, 12)     720         activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 8, 8, 12)     48          conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 8, 8, 12)     0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 8, 8, 12)     1296        activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_30 (Dropout)            (None, 8, 8, 12)     0           conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_28 (Concatenate)    (None, 8, 8, 72)     0           concatenate_27[0][0]             \n",
      "                                                                 dropout_30[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 8, 8, 72)     288         concatenate_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 8, 8, 72)     0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 8, 8, 12)     864         activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 8, 8, 12)     48          conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 8, 8, 12)     0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 8, 8, 12)     1296        activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_31 (Dropout)            (None, 8, 8, 12)     0           conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_29 (Concatenate)    (None, 8, 8, 84)     0           concatenate_28[0][0]             \n",
      "                                                                 dropout_31[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 8, 8, 84)     336         concatenate_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 8, 8, 84)     0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 8, 8, 12)     1008        activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 8, 8, 12)     48          conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 8, 8, 12)     0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 8, 8, 12)     1296        activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_32 (Dropout)            (None, 8, 8, 12)     0           conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_30 (Concatenate)    (None, 8, 8, 96)     0           concatenate_29[0][0]             \n",
      "                                                                 dropout_32[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 8, 8, 96)     384         concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 8, 8, 96)     0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 8, 8, 12)     1152        activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 8, 8, 12)     48          conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 8, 8, 12)     0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 8, 8, 12)     1296        activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_33 (Dropout)            (None, 8, 8, 12)     0           conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_31 (Concatenate)    (None, 8, 8, 108)    0           concatenate_30[0][0]             \n",
      "                                                                 dropout_33[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 8, 8, 108)    432         concatenate_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 8, 8, 108)    0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 8, 8, 12)     1296        activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 8, 8, 12)     48          conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 8, 8, 12)     0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 8, 8, 12)     1296        activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_34 (Dropout)            (None, 8, 8, 12)     0           conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_32 (Concatenate)    (None, 8, 8, 120)    0           concatenate_31[0][0]             \n",
      "                                                                 dropout_34[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 8, 8, 120)    480         concatenate_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 8, 8, 120)    0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 8, 8, 12)     1440        activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 8, 8, 12)     48          conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 8, 8, 12)     0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 8, 8, 12)     1296        activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_35 (Dropout)            (None, 8, 8, 12)     0           conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_33 (Concatenate)    (None, 8, 8, 132)    0           concatenate_32[0][0]             \n",
      "                                                                 dropout_35[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 8, 8, 132)    528         concatenate_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 8, 8, 132)    0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 8, 8, 12)     1584        activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 8, 8, 12)     48          conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 8, 8, 12)     0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 8, 8, 12)     1296        activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_36 (Dropout)            (None, 8, 8, 12)     0           conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_34 (Concatenate)    (None, 8, 8, 144)    0           concatenate_33[0][0]             \n",
      "                                                                 dropout_36[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 8, 8, 144)    576         concatenate_34[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 8, 8, 144)    0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 8, 8, 12)     1728        activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 8, 8, 12)     48          conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 8, 8, 12)     0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 8, 8, 12)     1296        activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, 8, 8, 12)     0           conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_35 (Concatenate)    (None, 8, 8, 156)    0           concatenate_34[0][0]             \n",
      "                                                                 dropout_37[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 8, 8, 156)    624         concatenate_35[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 8, 8, 156)    0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 8, 8, 12)     1872        activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_38 (Dropout)            (None, 8, 8, 12)     0           conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 4, 4, 12)     0           dropout_38[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 4, 4, 12)     48          average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 4, 4, 12)     0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 4, 4, 12)     144         activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 4, 4, 12)     48          conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 4, 4, 12)     0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 4, 4, 12)     1296        activation_76[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_39 (Dropout)            (None, 4, 4, 12)     0           conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_36 (Concatenate)    (None, 4, 4, 24)     0           average_pooling2d_2[0][0]        \n",
      "                                                                 dropout_39[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 4, 4, 24)     96          concatenate_36[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 4, 4, 24)     0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 4, 4, 12)     288         activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 4, 4, 12)     48          conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 4, 4, 12)     0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 4, 4, 12)     1296        activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_40 (Dropout)            (None, 4, 4, 12)     0           conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_37 (Concatenate)    (None, 4, 4, 36)     0           concatenate_36[0][0]             \n",
      "                                                                 dropout_40[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 4, 4, 36)     144         concatenate_37[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 4, 4, 36)     0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 4, 4, 12)     432         activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 4, 4, 12)     48          conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 4, 4, 12)     0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 4, 4, 12)     1296        activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_41 (Dropout)            (None, 4, 4, 12)     0           conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_38 (Concatenate)    (None, 4, 4, 48)     0           concatenate_37[0][0]             \n",
      "                                                                 dropout_41[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 4, 4, 48)     192         concatenate_38[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 4, 4, 48)     0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 4, 4, 12)     576         activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 4, 4, 12)     48          conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 4, 4, 12)     0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 4, 4, 12)     1296        activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_42 (Dropout)            (None, 4, 4, 12)     0           conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_39 (Concatenate)    (None, 4, 4, 60)     0           concatenate_38[0][0]             \n",
      "                                                                 dropout_42[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 4, 4, 60)     240         concatenate_39[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 4, 4, 60)     0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 4, 4, 12)     720         activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 4, 4, 12)     48          conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 4, 4, 12)     0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 4, 4, 12)     1296        activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_43 (Dropout)            (None, 4, 4, 12)     0           conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_40 (Concatenate)    (None, 4, 4, 72)     0           concatenate_39[0][0]             \n",
      "                                                                 dropout_43[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 4, 4, 72)     288         concatenate_40[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 4, 4, 72)     0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 4, 4, 12)     864         activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 4, 4, 12)     48          conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 4, 4, 12)     0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 4, 4, 12)     1296        activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_44 (Dropout)            (None, 4, 4, 12)     0           conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_41 (Concatenate)    (None, 4, 4, 84)     0           concatenate_40[0][0]             \n",
      "                                                                 dropout_44[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 4, 4, 84)     336         concatenate_41[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 4, 4, 84)     0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 4, 4, 12)     1008        activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 4, 4, 12)     48          conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 4, 4, 12)     0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 4, 4, 12)     1296        activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_45 (Dropout)            (None, 4, 4, 12)     0           conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_42 (Concatenate)    (None, 4, 4, 96)     0           concatenate_41[0][0]             \n",
      "                                                                 dropout_45[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 4, 4, 96)     384         concatenate_42[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 4, 4, 96)     0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 4, 4, 12)     1152        activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 4, 4, 12)     48          conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 4, 4, 12)     0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 4, 4, 12)     1296        activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_46 (Dropout)            (None, 4, 4, 12)     0           conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_43 (Concatenate)    (None, 4, 4, 108)    0           concatenate_42[0][0]             \n",
      "                                                                 dropout_46[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 4, 4, 108)    432         concatenate_43[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 4, 4, 108)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 4, 4, 12)     1296        activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 4, 4, 12)     48          conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 4, 4, 12)     0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 4, 4, 12)     1296        activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_47 (Dropout)            (None, 4, 4, 12)     0           conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_44 (Concatenate)    (None, 4, 4, 120)    0           concatenate_43[0][0]             \n",
      "                                                                 dropout_47[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 4, 4, 120)    480         concatenate_44[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 4, 4, 120)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 4, 4, 12)     1440        activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 4, 4, 12)     48          conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 4, 4, 12)     0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 4, 4, 12)     1296        activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_48 (Dropout)            (None, 4, 4, 12)     0           conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_45 (Concatenate)    (None, 4, 4, 132)    0           concatenate_44[0][0]             \n",
      "                                                                 dropout_48[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 4, 4, 132)    528         concatenate_45[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 4, 4, 132)    0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 4, 4, 12)     1584        activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 4, 4, 12)     48          conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 4, 4, 12)     0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 4, 4, 12)     1296        activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_49 (Dropout)            (None, 4, 4, 12)     0           conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_46 (Concatenate)    (None, 4, 4, 144)    0           concatenate_45[0][0]             \n",
      "                                                                 dropout_49[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 4, 4, 144)    576         concatenate_46[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 4, 4, 144)    0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 4, 4, 12)     1728        activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 4, 4, 12)     48          conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 4, 4, 12)     0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 4, 4, 12)     1296        activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_50 (Dropout)            (None, 4, 4, 12)     0           conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_47 (Concatenate)    (None, 4, 4, 156)    0           concatenate_46[0][0]             \n",
      "                                                                 dropout_50[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 4, 4, 156)    624         concatenate_47[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 4, 4, 156)    0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 2, 2, 156)    0           activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 624)          0           average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           6250        flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 141,922\n",
      "Trainable params: 131,722\n",
      "Non-trainable params: 10,200\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3 = Model(inputs = [input], outputs = [output])\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BEfe2rDw02fy",
    "outputId": "5408364f-2412-4100-ac40-2038a79c5523"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "406\n"
     ]
    }
   ],
   "source": [
    "print(len(model3.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WCsFCQe302cF",
    "outputId": "f52ea4a2-35c5-48e2-9691-a9bd81a79008"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "390/390 [==============================] - 76s 174ms/step - loss: 1.8787 - accuracy: 0.3063 - val_loss: 6.2094 - val_accuracy: 0.1329\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.13290, saving model to weights.best.hdf5\n",
      "Epoch 2/100\n",
      "390/390 [==============================] - 65s 166ms/step - loss: 1.5245 - accuracy: 0.4403 - val_loss: 1.9439 - val_accuracy: 0.4002\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.13290 to 0.40020, saving model to weights.best.hdf5\n",
      "Epoch 3/100\n",
      "390/390 [==============================] - 65s 167ms/step - loss: 1.3421 - accuracy: 0.5108 - val_loss: 3.8294 - val_accuracy: 0.3237\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.40020\n",
      "Epoch 4/100\n",
      "390/390 [==============================] - 65s 167ms/step - loss: 1.2104 - accuracy: 0.5635 - val_loss: 2.2493 - val_accuracy: 0.4519\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.40020 to 0.45190, saving model to weights.best.hdf5\n",
      "Epoch 5/100\n",
      "390/390 [==============================] - 65s 166ms/step - loss: 1.1075 - accuracy: 0.6057 - val_loss: 1.7633 - val_accuracy: 0.5227\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.45190 to 0.52270, saving model to weights.best.hdf5\n",
      "Epoch 6/100\n",
      "390/390 [==============================] - 65s 166ms/step - loss: 1.0290 - accuracy: 0.6315 - val_loss: 1.4483 - val_accuracy: 0.5767\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.52270 to 0.57670, saving model to weights.best.hdf5\n",
      "Epoch 7/100\n",
      "390/390 [==============================] - 65s 165ms/step - loss: 0.9777 - accuracy: 0.6519 - val_loss: 2.5660 - val_accuracy: 0.4636\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.57670\n",
      "Epoch 8/100\n",
      "390/390 [==============================] - 64s 164ms/step - loss: 0.9328 - accuracy: 0.6688 - val_loss: 1.8276 - val_accuracy: 0.5384\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.57670\n",
      "Epoch 9/100\n",
      "390/390 [==============================] - 65s 165ms/step - loss: 0.8982 - accuracy: 0.6822 - val_loss: 1.6682 - val_accuracy: 0.5601\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.57670\n",
      "Epoch 10/100\n",
      "390/390 [==============================] - 64s 165ms/step - loss: 0.8749 - accuracy: 0.6896 - val_loss: 1.3930 - val_accuracy: 0.6313\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.57670 to 0.63130, saving model to weights.best.hdf5\n",
      "Epoch 11/100\n",
      "390/390 [==============================] - 64s 165ms/step - loss: 0.8522 - accuracy: 0.6970 - val_loss: 1.1654 - val_accuracy: 0.6492\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.63130 to 0.64920, saving model to weights.best.hdf5\n",
      "Epoch 12/100\n",
      "390/390 [==============================] - 64s 165ms/step - loss: 0.8241 - accuracy: 0.7086 - val_loss: 1.5537 - val_accuracy: 0.6059\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.64920\n",
      "Epoch 13/100\n",
      "390/390 [==============================] - 65s 166ms/step - loss: 0.8022 - accuracy: 0.7167 - val_loss: 1.3158 - val_accuracy: 0.5879\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.64920\n",
      "Epoch 14/100\n",
      "390/390 [==============================] - 65s 165ms/step - loss: 0.7882 - accuracy: 0.7229 - val_loss: 1.4757 - val_accuracy: 0.6051\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.64920\n",
      "Epoch 15/100\n",
      "390/390 [==============================] - 65s 166ms/step - loss: 0.7644 - accuracy: 0.7320 - val_loss: 0.9961 - val_accuracy: 0.6942\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.64920 to 0.69420, saving model to weights.best.hdf5\n",
      "Epoch 16/100\n",
      "390/390 [==============================] - 65s 166ms/step - loss: 0.7446 - accuracy: 0.7390 - val_loss: 1.0217 - val_accuracy: 0.7059\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.69420 to 0.70590, saving model to weights.best.hdf5\n",
      "Epoch 17/100\n",
      "390/390 [==============================] - 65s 166ms/step - loss: 0.7307 - accuracy: 0.7432 - val_loss: 0.9654 - val_accuracy: 0.6975\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.70590\n",
      "Epoch 18/100\n",
      "390/390 [==============================] - 65s 166ms/step - loss: 0.7159 - accuracy: 0.7480 - val_loss: 1.2995 - val_accuracy: 0.6513\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.70590\n",
      "Epoch 19/100\n",
      "390/390 [==============================] - 64s 165ms/step - loss: 0.7013 - accuracy: 0.7530 - val_loss: 1.0214 - val_accuracy: 0.6978\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.70590\n",
      "Epoch 20/100\n",
      "390/390 [==============================] - 64s 164ms/step - loss: 0.6920 - accuracy: 0.7567 - val_loss: 1.3233 - val_accuracy: 0.6280\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.70590\n",
      "Epoch 21/100\n",
      "390/390 [==============================] - 64s 163ms/step - loss: 0.6844 - accuracy: 0.7609 - val_loss: 0.9723 - val_accuracy: 0.7109\n",
      "\n",
      "Epoch 00021: val_accuracy improved from 0.70590 to 0.71090, saving model to weights.best.hdf5\n",
      "Epoch 22/100\n",
      "390/390 [==============================] - 64s 163ms/step - loss: 0.6724 - accuracy: 0.7660 - val_loss: 0.7707 - val_accuracy: 0.7574\n",
      "\n",
      "Epoch 00022: val_accuracy improved from 0.71090 to 0.75740, saving model to weights.best.hdf5\n",
      "Epoch 23/100\n",
      "390/390 [==============================] - 64s 163ms/step - loss: 0.6639 - accuracy: 0.7681 - val_loss: 0.9687 - val_accuracy: 0.7260\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.75740\n",
      "Epoch 24/100\n",
      "390/390 [==============================] - 64s 164ms/step - loss: 0.6538 - accuracy: 0.7721 - val_loss: 0.9126 - val_accuracy: 0.7317\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.75740\n",
      "Epoch 25/100\n",
      "390/390 [==============================] - 64s 163ms/step - loss: 0.6481 - accuracy: 0.7726 - val_loss: 1.8253 - val_accuracy: 0.6180\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.75740\n",
      "Epoch 26/100\n",
      "390/390 [==============================] - 64s 163ms/step - loss: 0.5803 - accuracy: 0.7983 - val_loss: 0.6085 - val_accuracy: 0.8065\n",
      "\n",
      "Epoch 00026: val_accuracy improved from 0.75740 to 0.80650, saving model to weights.best.hdf5\n",
      "Epoch 27/100\n",
      "390/390 [==============================] - 64s 164ms/step - loss: 0.5542 - accuracy: 0.8054 - val_loss: 0.6685 - val_accuracy: 0.7945\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.80650\n",
      "Epoch 28/100\n",
      "390/390 [==============================] - 64s 163ms/step - loss: 0.5452 - accuracy: 0.8079 - val_loss: 0.7349 - val_accuracy: 0.7816\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.80650\n",
      "Epoch 29/100\n",
      "390/390 [==============================] - 63s 163ms/step - loss: 0.5400 - accuracy: 0.8101 - val_loss: 0.7039 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.80650\n",
      "Epoch 30/100\n",
      "390/390 [==============================] - 63s 163ms/step - loss: 0.5333 - accuracy: 0.8130 - val_loss: 0.6732 - val_accuracy: 0.7933\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.80650\n",
      "Epoch 31/100\n",
      "390/390 [==============================] - 63s 162ms/step - loss: 0.5295 - accuracy: 0.8153 - val_loss: 0.5967 - val_accuracy: 0.8126\n",
      "\n",
      "Epoch 00031: val_accuracy improved from 0.80650 to 0.81260, saving model to weights.best.hdf5\n",
      "Epoch 32/100\n",
      "390/390 [==============================] - 64s 163ms/step - loss: 0.5266 - accuracy: 0.8149 - val_loss: 0.6517 - val_accuracy: 0.8036\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.81260\n",
      "Epoch 33/100\n",
      "390/390 [==============================] - 63s 162ms/step - loss: 0.5259 - accuracy: 0.8179 - val_loss: 0.7121 - val_accuracy: 0.7878\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.81260\n",
      "Epoch 34/100\n",
      "390/390 [==============================] - 63s 162ms/step - loss: 0.5200 - accuracy: 0.8164 - val_loss: 0.6949 - val_accuracy: 0.7905\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.81260\n",
      "Epoch 35/100\n",
      "390/390 [==============================] - 64s 164ms/step - loss: 0.5119 - accuracy: 0.8211 - val_loss: 0.6087 - val_accuracy: 0.8097\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.81260\n",
      "Epoch 36/100\n",
      "390/390 [==============================] - 64s 164ms/step - loss: 0.5189 - accuracy: 0.8174 - val_loss: 0.5921 - val_accuracy: 0.8145\n",
      "\n",
      "Epoch 00036: val_accuracy improved from 0.81260 to 0.81450, saving model to weights.best.hdf5\n",
      "Epoch 37/100\n",
      "390/390 [==============================] - 64s 164ms/step - loss: 0.5131 - accuracy: 0.8210 - val_loss: 0.6484 - val_accuracy: 0.8044\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.81450\n",
      "Epoch 38/100\n",
      "390/390 [==============================] - 64s 165ms/step - loss: 0.5070 - accuracy: 0.8235 - val_loss: 0.6497 - val_accuracy: 0.8017\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.81450\n",
      "Epoch 39/100\n",
      "390/390 [==============================] - 64s 165ms/step - loss: 0.5071 - accuracy: 0.8247 - val_loss: 0.6591 - val_accuracy: 0.8039\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.81450\n",
      "Epoch 40/100\n",
      "390/390 [==============================] - 64s 165ms/step - loss: 0.5062 - accuracy: 0.8222 - val_loss: 0.6059 - val_accuracy: 0.8115\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.81450\n",
      "Epoch 41/100\n",
      "390/390 [==============================] - 64s 163ms/step - loss: 0.5033 - accuracy: 0.8236 - val_loss: 0.6382 - val_accuracy: 0.8071\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.81450\n",
      "Epoch 42/100\n",
      "390/390 [==============================] - 63s 162ms/step - loss: 0.5019 - accuracy: 0.8264 - val_loss: 0.6656 - val_accuracy: 0.8002\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.81450\n",
      "Epoch 43/100\n",
      "390/390 [==============================] - 64s 163ms/step - loss: 0.5012 - accuracy: 0.8257 - val_loss: 0.6749 - val_accuracy: 0.7962\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.81450\n",
      "Epoch 44/100\n",
      "390/390 [==============================] - 64s 163ms/step - loss: 0.5013 - accuracy: 0.8232 - val_loss: 0.6785 - val_accuracy: 0.7997\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.81450\n",
      "Epoch 45/100\n",
      "390/390 [==============================] - 64s 163ms/step - loss: 0.4997 - accuracy: 0.8261 - val_loss: 0.5985 - val_accuracy: 0.8147\n",
      "\n",
      "Epoch 00045: val_accuracy improved from 0.81450 to 0.81470, saving model to weights.best.hdf5\n",
      "Epoch 46/100\n",
      "390/390 [==============================] - 63s 162ms/step - loss: 0.4949 - accuracy: 0.8271 - val_loss: 0.6376 - val_accuracy: 0.8057\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.81470\n",
      "Epoch 47/100\n",
      "390/390 [==============================] - 64s 163ms/step - loss: 0.4920 - accuracy: 0.8272 - val_loss: 0.6769 - val_accuracy: 0.8001\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.81470\n",
      "Epoch 48/100\n",
      "390/390 [==============================] - 64s 163ms/step - loss: 0.4907 - accuracy: 0.8269 - val_loss: 0.5599 - val_accuracy: 0.8259\n",
      "\n",
      "Epoch 00048: val_accuracy improved from 0.81470 to 0.82590, saving model to weights.best.hdf5\n",
      "Epoch 49/100\n",
      "390/390 [==============================] - 64s 163ms/step - loss: 0.4904 - accuracy: 0.8281 - val_loss: 0.5944 - val_accuracy: 0.8191\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.82590\n",
      "Epoch 50/100\n",
      "390/390 [==============================] - 64s 163ms/step - loss: 0.4923 - accuracy: 0.8295 - val_loss: 0.6196 - val_accuracy: 0.8115\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.82590\n",
      "Epoch 51/100\n",
      "390/390 [==============================] - 64s 163ms/step - loss: 0.4771 - accuracy: 0.8336 - val_loss: 0.5877 - val_accuracy: 0.8199\n",
      "\n",
      "Epoch 00051: val_accuracy did not improve from 0.82590\n",
      "Epoch 52/100\n",
      "390/390 [==============================] - 64s 164ms/step - loss: 0.4797 - accuracy: 0.8317 - val_loss: 0.5976 - val_accuracy: 0.8197\n",
      "\n",
      "Epoch 00052: val_accuracy did not improve from 0.82590\n",
      "Epoch 53/100\n",
      "390/390 [==============================] - 63s 163ms/step - loss: 0.4778 - accuracy: 0.8332 - val_loss: 0.6047 - val_accuracy: 0.8172\n",
      "\n",
      "Epoch 00053: val_accuracy did not improve from 0.82590\n",
      "Epoch 54/100\n",
      "390/390 [==============================] - 64s 163ms/step - loss: 0.4803 - accuracy: 0.8328 - val_loss: 0.5944 - val_accuracy: 0.8193\n",
      "\n",
      "Epoch 00054: val_accuracy did not improve from 0.82590\n",
      "Epoch 55/100\n",
      "390/390 [==============================] - 64s 164ms/step - loss: 0.4740 - accuracy: 0.8350 - val_loss: 0.6027 - val_accuracy: 0.8182\n",
      "\n",
      "Epoch 00055: val_accuracy did not improve from 0.82590\n",
      "Epoch 56/100\n",
      "390/390 [==============================] - 63s 162ms/step - loss: 0.4762 - accuracy: 0.8324 - val_loss: 0.5926 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00056: val_accuracy did not improve from 0.82590\n",
      "Epoch 57/100\n",
      "390/390 [==============================] - 64s 163ms/step - loss: 0.4754 - accuracy: 0.8337 - val_loss: 0.5978 - val_accuracy: 0.8182\n",
      "\n",
      "Epoch 00057: val_accuracy did not improve from 0.82590\n",
      "Epoch 58/100\n",
      "390/390 [==============================] - 64s 164ms/step - loss: 0.4789 - accuracy: 0.8337 - val_loss: 0.5979 - val_accuracy: 0.8188\n",
      "\n",
      "Epoch 00058: val_accuracy did not improve from 0.82590\n",
      "Epoch 59/100\n",
      "390/390 [==============================] - 64s 164ms/step - loss: 0.4787 - accuracy: 0.8340 - val_loss: 0.6087 - val_accuracy: 0.8176\n",
      "\n",
      "Epoch 00059: val_accuracy did not improve from 0.82590\n",
      "Epoch 60/100\n",
      "390/390 [==============================] - 64s 165ms/step - loss: 0.4762 - accuracy: 0.8338 - val_loss: 0.6094 - val_accuracy: 0.8173\n",
      "\n",
      "Epoch 00060: val_accuracy did not improve from 0.82590\n",
      "Epoch 61/100\n",
      "390/390 [==============================] - 64s 165ms/step - loss: 0.4764 - accuracy: 0.8326 - val_loss: 0.6118 - val_accuracy: 0.8167\n",
      "\n",
      "Epoch 00061: val_accuracy did not improve from 0.82590\n",
      "Epoch 62/100\n",
      "390/390 [==============================] - 64s 164ms/step - loss: 0.4737 - accuracy: 0.8348 - val_loss: 0.5979 - val_accuracy: 0.8186\n",
      "\n",
      "Epoch 00062: val_accuracy did not improve from 0.82590\n",
      "Epoch 63/100\n",
      "390/390 [==============================] - 64s 164ms/step - loss: 0.4763 - accuracy: 0.8335 - val_loss: 0.5987 - val_accuracy: 0.8196\n",
      "\n",
      "Epoch 00063: val_accuracy did not improve from 0.82590\n",
      "Epoch 64/100\n",
      "390/390 [==============================] - 64s 163ms/step - loss: 0.4751 - accuracy: 0.8336 - val_loss: 0.5927 - val_accuracy: 0.8203\n",
      "\n",
      "Epoch 00064: val_accuracy did not improve from 0.82590\n",
      "Epoch 65/100\n",
      "390/390 [==============================] - 63s 162ms/step - loss: 0.4737 - accuracy: 0.8345 - val_loss: 0.6007 - val_accuracy: 0.8183\n",
      "\n",
      "Epoch 00065: val_accuracy did not improve from 0.82590\n",
      "Epoch 66/100\n",
      "390/390 [==============================] - 63s 162ms/step - loss: 0.4755 - accuracy: 0.8351 - val_loss: 0.6137 - val_accuracy: 0.8152\n",
      "\n",
      "Epoch 00066: val_accuracy did not improve from 0.82590\n",
      "Epoch 67/100\n",
      "390/390 [==============================] - 63s 162ms/step - loss: 0.4724 - accuracy: 0.8345 - val_loss: 0.6001 - val_accuracy: 0.8194\n",
      "\n",
      "Epoch 00067: val_accuracy did not improve from 0.82590\n",
      "Epoch 68/100\n",
      "390/390 [==============================] - 64s 163ms/step - loss: 0.4731 - accuracy: 0.8344 - val_loss: 0.5974 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00068: val_accuracy did not improve from 0.82590\n",
      "Epoch 69/100\n",
      "390/390 [==============================] - 63s 162ms/step - loss: 0.4721 - accuracy: 0.8328 - val_loss: 0.6013 - val_accuracy: 0.8185\n",
      "\n",
      "Epoch 00069: val_accuracy did not improve from 0.82590\n",
      "Epoch 70/100\n",
      "390/390 [==============================] - 64s 163ms/step - loss: 0.4708 - accuracy: 0.8332 - val_loss: 0.5925 - val_accuracy: 0.8204\n",
      "\n",
      "Epoch 00070: val_accuracy did not improve from 0.82590\n",
      "Epoch 71/100\n",
      "390/390 [==============================] - 64s 164ms/step - loss: 0.4703 - accuracy: 0.8352 - val_loss: 0.5956 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00071: val_accuracy did not improve from 0.82590\n",
      "Epoch 72/100\n",
      "390/390 [==============================] - 63s 163ms/step - loss: 0.4741 - accuracy: 0.8340 - val_loss: 0.6019 - val_accuracy: 0.8192\n",
      "\n",
      "Epoch 00072: val_accuracy did not improve from 0.82590\n",
      "Epoch 73/100\n",
      "390/390 [==============================] - 64s 163ms/step - loss: 0.4769 - accuracy: 0.8342 - val_loss: 0.5974 - val_accuracy: 0.8196\n",
      "\n",
      "Epoch 00073: val_accuracy did not improve from 0.82590\n",
      "Epoch 74/100\n",
      "390/390 [==============================] - 64s 163ms/step - loss: 0.4732 - accuracy: 0.8349 - val_loss: 0.6004 - val_accuracy: 0.8193\n",
      "\n",
      "Epoch 00074: val_accuracy did not improve from 0.82590\n",
      "Epoch 75/100\n",
      "390/390 [==============================] - 64s 164ms/step - loss: 0.4754 - accuracy: 0.8328 - val_loss: 0.6164 - val_accuracy: 0.8165\n",
      "\n",
      "Epoch 00075: val_accuracy did not improve from 0.82590\n",
      "Epoch 76/100\n",
      "390/390 [==============================] - 64s 163ms/step - loss: 0.4711 - accuracy: 0.8346 - val_loss: 0.5940 - val_accuracy: 0.8194\n",
      "\n",
      "Epoch 00076: val_accuracy did not improve from 0.82590\n",
      "Epoch 77/100\n",
      "390/390 [==============================] - 64s 163ms/step - loss: 0.4659 - accuracy: 0.8373 - val_loss: 0.6167 - val_accuracy: 0.8164\n",
      "\n",
      "Epoch 00077: val_accuracy did not improve from 0.82590\n",
      "Epoch 78/100\n",
      "390/390 [==============================] - 64s 163ms/step - loss: 0.4644 - accuracy: 0.8376 - val_loss: 0.5916 - val_accuracy: 0.8205\n",
      "\n",
      "Epoch 00078: val_accuracy did not improve from 0.82590\n",
      "Epoch 79/100\n",
      "390/390 [==============================] - 64s 164ms/step - loss: 0.4671 - accuracy: 0.8366 - val_loss: 0.5899 - val_accuracy: 0.8204\n",
      "\n",
      "Epoch 00079: val_accuracy did not improve from 0.82590\n",
      "Epoch 80/100\n",
      "390/390 [==============================] - 64s 165ms/step - loss: 0.4735 - accuracy: 0.8352 - val_loss: 0.5945 - val_accuracy: 0.8196\n",
      "\n",
      "Epoch 00080: val_accuracy did not improve from 0.82590\n",
      "Epoch 81/100\n",
      "390/390 [==============================] - 64s 165ms/step - loss: 0.4684 - accuracy: 0.8353 - val_loss: 0.5949 - val_accuracy: 0.8207\n",
      "\n",
      "Epoch 00081: val_accuracy did not improve from 0.82590\n",
      "Epoch 82/100\n",
      "390/390 [==============================] - 64s 163ms/step - loss: 0.4709 - accuracy: 0.8374 - val_loss: 0.5980 - val_accuracy: 0.8203\n",
      "\n",
      "Epoch 00082: val_accuracy did not improve from 0.82590\n",
      "Epoch 83/100\n",
      "390/390 [==============================] - 64s 163ms/step - loss: 0.4705 - accuracy: 0.8367 - val_loss: 0.5977 - val_accuracy: 0.8198\n",
      "\n",
      "Epoch 00083: val_accuracy did not improve from 0.82590\n",
      "Epoch 84/100\n",
      "390/390 [==============================] - 64s 164ms/step - loss: 0.4679 - accuracy: 0.8338 - val_loss: 0.5871 - val_accuracy: 0.8220\n",
      "\n",
      "Epoch 00084: val_accuracy did not improve from 0.82590\n",
      "Epoch 85/100\n",
      "390/390 [==============================] - 63s 162ms/step - loss: 0.4693 - accuracy: 0.8369 - val_loss: 0.5832 - val_accuracy: 0.8221\n",
      "\n",
      "Epoch 00085: val_accuracy did not improve from 0.82590\n",
      "Epoch 86/100\n",
      "390/390 [==============================] - 64s 163ms/step - loss: 0.4712 - accuracy: 0.8348 - val_loss: 0.5976 - val_accuracy: 0.8199\n",
      "\n",
      "Epoch 00086: val_accuracy did not improve from 0.82590\n",
      "Epoch 87/100\n",
      "390/390 [==============================] - 64s 164ms/step - loss: 0.4734 - accuracy: 0.8344 - val_loss: 0.5842 - val_accuracy: 0.8223\n",
      "\n",
      "Epoch 00087: val_accuracy did not improve from 0.82590\n",
      "Epoch 88/100\n",
      "390/390 [==============================] - 64s 163ms/step - loss: 0.4667 - accuracy: 0.8361 - val_loss: 0.6003 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00088: val_accuracy did not improve from 0.82590\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f58c765c350>"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model3.fit(aug.flow(X_train,y_train,batch_size=batch_size),epochs=nb_epoch,batch_size=batch_size,verbose=1,\n",
    "           steps_per_epoch=(len(X_train)//batch_size),\n",
    "           callbacks=[reduce_lr,lr_scheduler,csv_logger,early_stop,model_checkpoint],\n",
    "           validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V8ESkKxkd0oa"
   },
   "source": [
    "### 2.5 Growth rate(num_filter)=32, compression = 0.7, Number of blocks = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6_PUmIXe02Zn"
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 64\n",
    "num_classes = 10\n",
    "nb_epoch = 100\n",
    "l = 12\n",
    "num_filter = 32\n",
    "compression = 0.7\n",
    "dropout_rate = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DbZg50Dy02Wp"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "#https://machinelearningmastery.com/check-point-deep-learning-models-keras/\n",
    "filepath=\"model4_weights.best.hdf5\"\n",
    "model_checkpoint = ModelCheckpoint(filepath,monitor='val_accuracy',save_best_only=True,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oY0FeEmF02T6"
   },
   "outputs": [],
   "source": [
    "input = layers.Input(shape=(img_height, img_width, channel,))\n",
    "First_Conv2D = layers.Conv2D(num_filter, (3,3), use_bias=False ,padding='same')(input)\n",
    "\n",
    "First_Block = denseblock(First_Conv2D, num_filter, dropout_rate)\n",
    "First_Transition = transition(First_Block, num_filter, dropout_rate)\n",
    "\n",
    "Second_Block = denseblock(First_Transition, num_filter, dropout_rate)\n",
    "Second_Transition = transition(Second_Block, num_filter, dropout_rate)\n",
    "\n",
    "Third_Block = denseblock(Second_Transition, num_filter, dropout_rate)\n",
    "Third_Transition = transition(Third_Block, num_filter, dropout_rate)\n",
    "\n",
    "Last_Block = denseblock(Third_Transition,  num_filter, dropout_rate)\n",
    "output = output_layer(Last_Block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UL_gh4ci02Rn",
    "outputId": "024711e6-f7cc-40d9-f972-d8fa98ad014b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 32, 32, 32)   864         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 32, 32, 32)   128         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 32, 32, 32)   0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 32, 32, 22)   704         activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 32, 22)   88          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 32, 32, 22)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 22)   4356        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 32, 32, 22)   0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 32, 32, 54)   0           conv2d[0][0]                     \n",
      "                                                                 dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 54)   216         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 32, 32, 54)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 32, 22)   1188        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 32, 22)   88          conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 32, 32, 22)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 32, 32, 22)   4356        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 32, 32, 22)   0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 32, 32, 76)   0           concatenate[0][0]                \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 32, 32, 76)   304         concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 32, 32, 76)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 32, 32, 22)   1672        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32, 32, 22)   88          conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 32, 32, 22)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 22)   4356        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 32, 32, 22)   0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 32, 32, 98)   0           concatenate_1[0][0]              \n",
      "                                                                 dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 32, 32, 98)   392         concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 32, 32, 98)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 22)   2156        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 32, 32, 22)   88          conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 32, 32, 22)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 22)   4356        activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 32, 32, 22)   0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 32, 32, 120)  0           concatenate_2[0][0]              \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 32, 120)  480         concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 32, 32, 120)  0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 22)   2640        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 32, 32, 22)   88          conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 32, 32, 22)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 32, 32, 22)   4356        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 32, 32, 22)   0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 32, 32, 142)  0           concatenate_3[0][0]              \n",
      "                                                                 dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 32, 32, 142)  568         concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 32, 32, 142)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 32, 32, 22)   3124        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 32, 32, 22)   88          conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 32, 32, 22)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 32, 32, 22)   4356        activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 32, 32, 22)   0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 32, 32, 164)  0           concatenate_4[0][0]              \n",
      "                                                                 dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 32, 32, 164)  656         concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 32, 32, 164)  0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 32, 32, 22)   3608        activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 32, 32, 22)   88          conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 32, 32, 22)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 32, 32, 22)   4356        activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 32, 32, 22)   0           conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 32, 32, 186)  0           concatenate_5[0][0]              \n",
      "                                                                 dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 32, 32, 186)  744         concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 32, 32, 186)  0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 32, 32, 22)   4092        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 32, 32, 22)   88          conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 32, 32, 22)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 32, 32, 22)   4356        activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 32, 32, 22)   0           conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 32, 32, 208)  0           concatenate_6[0][0]              \n",
      "                                                                 dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 32, 32, 208)  832         concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 32, 32, 208)  0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 32, 32, 22)   4576        activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 32, 32, 22)   88          conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 32, 32, 22)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 32, 32, 22)   4356        activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 32, 32, 22)   0           conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 32, 32, 230)  0           concatenate_7[0][0]              \n",
      "                                                                 dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 32, 32, 230)  920         concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 32, 32, 230)  0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 32, 32, 22)   5060        activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 32, 32, 22)   88          conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 32, 32, 22)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 32, 32, 22)   4356        activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 32, 32, 22)   0           conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 32, 32, 252)  0           concatenate_8[0][0]              \n",
      "                                                                 dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 32, 32, 252)  1008        concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 32, 32, 252)  0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 32, 32, 22)   5544        activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 32, 32, 22)   88          conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 32, 32, 22)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 32, 32, 22)   4356        activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 32, 32, 22)   0           conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 32, 32, 274)  0           concatenate_9[0][0]              \n",
      "                                                                 dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 32, 32, 274)  1096        concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 32, 32, 274)  0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 32, 32, 22)   6028        activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 32, 32, 22)   88          conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 32, 32, 22)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 32, 32, 22)   4356        activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 32, 32, 22)   0           conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 32, 32, 296)  0           concatenate_10[0][0]             \n",
      "                                                                 dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 32, 32, 296)  1184        concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 32, 32, 296)  0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 32, 32, 22)   6512        activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 32, 32, 22)   0           conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 16, 16, 22)   0           dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 16, 16, 22)   88          average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 16, 16, 22)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 16, 16, 22)   484         activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 16, 16, 22)   88          conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 16, 16, 22)   0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 16, 16, 22)   4356        activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 16, 16, 22)   0           conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 16, 16, 44)   0           average_pooling2d[0][0]          \n",
      "                                                                 dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 16, 16, 44)   176         concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 16, 16, 44)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 16, 16, 22)   968         activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 16, 16, 22)   88          conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 16, 16, 22)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 16, 16, 22)   4356        activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 16, 16, 22)   0           conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 16, 16, 66)   0           concatenate_12[0][0]             \n",
      "                                                                 dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 16, 16, 66)   264         concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 16, 16, 66)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 16, 16, 22)   1452        activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 16, 16, 22)   88          conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 16, 16, 22)   0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 16, 16, 22)   4356        activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 16, 16, 22)   0           conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 16, 16, 88)   0           concatenate_13[0][0]             \n",
      "                                                                 dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 16, 16, 88)   352         concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 16, 16, 88)   0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 16, 16, 22)   1936        activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 16, 16, 22)   88          conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 16, 16, 22)   0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 16, 16, 22)   4356        activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 16, 16, 22)   0           conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 16, 16, 110)  0           concatenate_14[0][0]             \n",
      "                                                                 dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 16, 16, 110)  440         concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 16, 16, 110)  0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 16, 16, 22)   2420        activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 16, 16, 22)   88          conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 16, 16, 22)   0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 16, 16, 22)   4356        activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 16, 16, 22)   0           conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 16, 16, 132)  0           concatenate_15[0][0]             \n",
      "                                                                 dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 16, 16, 132)  528         concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 16, 16, 132)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 16, 16, 22)   2904        activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 16, 16, 22)   88          conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 16, 16, 22)   0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 16, 16, 22)   4356        activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 16, 16, 22)   0           conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, 16, 16, 154)  0           concatenate_16[0][0]             \n",
      "                                                                 dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 16, 16, 154)  616         concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 16, 16, 154)  0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 16, 16, 22)   3388        activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 16, 16, 22)   88          conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 16, 16, 22)   0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 16, 16, 22)   4356        activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 16, 16, 22)   0           conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, 16, 16, 176)  0           concatenate_17[0][0]             \n",
      "                                                                 dropout_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 16, 16, 176)  704         concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 16, 16, 176)  0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 16, 16, 22)   3872        activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 16, 16, 22)   88          conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 16, 16, 22)   0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 16, 16, 22)   4356        activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 16, 16, 22)   0           conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, 16, 16, 198)  0           concatenate_18[0][0]             \n",
      "                                                                 dropout_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 16, 16, 198)  792         concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 16, 16, 198)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 16, 16, 22)   4356        activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 16, 16, 22)   88          conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 16, 16, 22)   0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 16, 16, 22)   4356        activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 16, 16, 22)   0           conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_20 (Concatenate)    (None, 16, 16, 220)  0           concatenate_19[0][0]             \n",
      "                                                                 dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 16, 16, 220)  880         concatenate_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 16, 16, 220)  0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 16, 16, 22)   4840        activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 16, 16, 22)   88          conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 16, 16, 22)   0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 16, 16, 22)   4356        activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 16, 16, 22)   0           conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_21 (Concatenate)    (None, 16, 16, 242)  0           concatenate_20[0][0]             \n",
      "                                                                 dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 16, 16, 242)  968         concatenate_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 16, 16, 242)  0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 16, 16, 22)   5324        activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 16, 16, 22)   88          conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 16, 16, 22)   0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 16, 16, 22)   4356        activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 16, 16, 22)   0           conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_22 (Concatenate)    (None, 16, 16, 264)  0           concatenate_21[0][0]             \n",
      "                                                                 dropout_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 16, 16, 264)  1056        concatenate_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 16, 16, 264)  0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 16, 16, 22)   5808        activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 16, 16, 22)   88          conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 16, 16, 22)   0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 16, 16, 22)   4356        activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 16, 16, 22)   0           conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_23 (Concatenate)    (None, 16, 16, 286)  0           concatenate_22[0][0]             \n",
      "                                                                 dropout_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 16, 16, 286)  1144        concatenate_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 16, 16, 286)  0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 16, 16, 22)   6292        activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, 16, 16, 22)   0           conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 8, 8, 22)     0           dropout_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 8, 8, 22)     88          average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 8, 8, 22)     0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 8, 8, 22)     484         activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 8, 8, 22)     88          conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 8, 8, 22)     0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 8, 8, 22)     4356        activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)            (None, 8, 8, 22)     0           conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_24 (Concatenate)    (None, 8, 8, 44)     0           average_pooling2d_1[0][0]        \n",
      "                                                                 dropout_26[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 8, 8, 44)     176         concatenate_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 8, 8, 44)     0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 8, 8, 22)     968         activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 8, 8, 22)     88          conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 8, 8, 22)     0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 8, 8, 22)     4356        activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)            (None, 8, 8, 22)     0           conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_25 (Concatenate)    (None, 8, 8, 66)     0           concatenate_24[0][0]             \n",
      "                                                                 dropout_27[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 8, 8, 66)     264         concatenate_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 8, 8, 66)     0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 8, 8, 22)     1452        activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 8, 8, 22)     88          conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 8, 8, 22)     0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 8, 8, 22)     4356        activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_28 (Dropout)            (None, 8, 8, 22)     0           conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_26 (Concatenate)    (None, 8, 8, 88)     0           concatenate_25[0][0]             \n",
      "                                                                 dropout_28[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 8, 8, 88)     352         concatenate_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 8, 8, 88)     0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 8, 8, 22)     1936        activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 8, 8, 22)     88          conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 8, 8, 22)     0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 8, 8, 22)     4356        activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_29 (Dropout)            (None, 8, 8, 22)     0           conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_27 (Concatenate)    (None, 8, 8, 110)    0           concatenate_26[0][0]             \n",
      "                                                                 dropout_29[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 8, 8, 110)    440         concatenate_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 8, 8, 110)    0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 8, 8, 22)     2420        activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 8, 8, 22)     88          conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 8, 8, 22)     0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 8, 8, 22)     4356        activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_30 (Dropout)            (None, 8, 8, 22)     0           conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_28 (Concatenate)    (None, 8, 8, 132)    0           concatenate_27[0][0]             \n",
      "                                                                 dropout_30[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 8, 8, 132)    528         concatenate_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 8, 8, 132)    0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 8, 8, 22)     2904        activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 8, 8, 22)     88          conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 8, 8, 22)     0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 8, 8, 22)     4356        activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_31 (Dropout)            (None, 8, 8, 22)     0           conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_29 (Concatenate)    (None, 8, 8, 154)    0           concatenate_28[0][0]             \n",
      "                                                                 dropout_31[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 8, 8, 154)    616         concatenate_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 8, 8, 154)    0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 8, 8, 22)     3388        activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 8, 8, 22)     88          conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 8, 8, 22)     0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 8, 8, 22)     4356        activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_32 (Dropout)            (None, 8, 8, 22)     0           conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_30 (Concatenate)    (None, 8, 8, 176)    0           concatenate_29[0][0]             \n",
      "                                                                 dropout_32[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 8, 8, 176)    704         concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 8, 8, 176)    0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 8, 8, 22)     3872        activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 8, 8, 22)     88          conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 8, 8, 22)     0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 8, 8, 22)     4356        activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_33 (Dropout)            (None, 8, 8, 22)     0           conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_31 (Concatenate)    (None, 8, 8, 198)    0           concatenate_30[0][0]             \n",
      "                                                                 dropout_33[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 8, 8, 198)    792         concatenate_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 8, 8, 198)    0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 8, 8, 22)     4356        activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 8, 8, 22)     88          conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 8, 8, 22)     0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 8, 8, 22)     4356        activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_34 (Dropout)            (None, 8, 8, 22)     0           conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_32 (Concatenate)    (None, 8, 8, 220)    0           concatenate_31[0][0]             \n",
      "                                                                 dropout_34[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 8, 8, 220)    880         concatenate_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 8, 8, 220)    0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 8, 8, 22)     4840        activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 8, 8, 22)     88          conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 8, 8, 22)     0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 8, 8, 22)     4356        activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_35 (Dropout)            (None, 8, 8, 22)     0           conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_33 (Concatenate)    (None, 8, 8, 242)    0           concatenate_32[0][0]             \n",
      "                                                                 dropout_35[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 8, 8, 242)    968         concatenate_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 8, 8, 242)    0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 8, 8, 22)     5324        activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 8, 8, 22)     88          conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 8, 8, 22)     0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 8, 8, 22)     4356        activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_36 (Dropout)            (None, 8, 8, 22)     0           conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_34 (Concatenate)    (None, 8, 8, 264)    0           concatenate_33[0][0]             \n",
      "                                                                 dropout_36[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 8, 8, 264)    1056        concatenate_34[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 8, 8, 264)    0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 8, 8, 22)     5808        activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 8, 8, 22)     88          conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 8, 8, 22)     0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 8, 8, 22)     4356        activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, 8, 8, 22)     0           conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_35 (Concatenate)    (None, 8, 8, 286)    0           concatenate_34[0][0]             \n",
      "                                                                 dropout_37[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 8, 8, 286)    1144        concatenate_35[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 8, 8, 286)    0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 8, 8, 22)     6292        activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_38 (Dropout)            (None, 8, 8, 22)     0           conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 4, 4, 22)     0           dropout_38[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 4, 4, 22)     88          average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 4, 4, 22)     0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 4, 4, 22)     484         activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 4, 4, 22)     88          conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 4, 4, 22)     0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 4, 4, 22)     4356        activation_76[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_39 (Dropout)            (None, 4, 4, 22)     0           conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_36 (Concatenate)    (None, 4, 4, 44)     0           average_pooling2d_2[0][0]        \n",
      "                                                                 dropout_39[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 4, 4, 44)     176         concatenate_36[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 4, 4, 44)     0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 4, 4, 22)     968         activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 4, 4, 22)     88          conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 4, 4, 22)     0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 4, 4, 22)     4356        activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_40 (Dropout)            (None, 4, 4, 22)     0           conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_37 (Concatenate)    (None, 4, 4, 66)     0           concatenate_36[0][0]             \n",
      "                                                                 dropout_40[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 4, 4, 66)     264         concatenate_37[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 4, 4, 66)     0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 4, 4, 22)     1452        activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 4, 4, 22)     88          conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 4, 4, 22)     0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 4, 4, 22)     4356        activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_41 (Dropout)            (None, 4, 4, 22)     0           conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_38 (Concatenate)    (None, 4, 4, 88)     0           concatenate_37[0][0]             \n",
      "                                                                 dropout_41[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 4, 4, 88)     352         concatenate_38[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 4, 4, 88)     0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 4, 4, 22)     1936        activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 4, 4, 22)     88          conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 4, 4, 22)     0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 4, 4, 22)     4356        activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_42 (Dropout)            (None, 4, 4, 22)     0           conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_39 (Concatenate)    (None, 4, 4, 110)    0           concatenate_38[0][0]             \n",
      "                                                                 dropout_42[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 4, 4, 110)    440         concatenate_39[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 4, 4, 110)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 4, 4, 22)     2420        activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 4, 4, 22)     88          conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 4, 4, 22)     0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 4, 4, 22)     4356        activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_43 (Dropout)            (None, 4, 4, 22)     0           conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_40 (Concatenate)    (None, 4, 4, 132)    0           concatenate_39[0][0]             \n",
      "                                                                 dropout_43[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 4, 4, 132)    528         concatenate_40[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 4, 4, 132)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 4, 4, 22)     2904        activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 4, 4, 22)     88          conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 4, 4, 22)     0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 4, 4, 22)     4356        activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_44 (Dropout)            (None, 4, 4, 22)     0           conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_41 (Concatenate)    (None, 4, 4, 154)    0           concatenate_40[0][0]             \n",
      "                                                                 dropout_44[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 4, 4, 154)    616         concatenate_41[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 4, 4, 154)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 4, 4, 22)     3388        activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 4, 4, 22)     88          conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 4, 4, 22)     0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 4, 4, 22)     4356        activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_45 (Dropout)            (None, 4, 4, 22)     0           conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_42 (Concatenate)    (None, 4, 4, 176)    0           concatenate_41[0][0]             \n",
      "                                                                 dropout_45[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 4, 4, 176)    704         concatenate_42[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 4, 4, 176)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 4, 4, 22)     3872        activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 4, 4, 22)     88          conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 4, 4, 22)     0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 4, 4, 22)     4356        activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_46 (Dropout)            (None, 4, 4, 22)     0           conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_43 (Concatenate)    (None, 4, 4, 198)    0           concatenate_42[0][0]             \n",
      "                                                                 dropout_46[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 4, 4, 198)    792         concatenate_43[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 4, 4, 198)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 4, 4, 22)     4356        activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 4, 4, 22)     88          conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 4, 4, 22)     0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 4, 4, 22)     4356        activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_47 (Dropout)            (None, 4, 4, 22)     0           conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_44 (Concatenate)    (None, 4, 4, 220)    0           concatenate_43[0][0]             \n",
      "                                                                 dropout_47[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 4, 4, 220)    880         concatenate_44[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 4, 4, 220)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 4, 4, 22)     4840        activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 4, 4, 22)     88          conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 4, 4, 22)     0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 4, 4, 22)     4356        activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_48 (Dropout)            (None, 4, 4, 22)     0           conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_45 (Concatenate)    (None, 4, 4, 242)    0           concatenate_44[0][0]             \n",
      "                                                                 dropout_48[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 4, 4, 242)    968         concatenate_45[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 4, 4, 242)    0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 4, 4, 22)     5324        activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 4, 4, 22)     88          conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 4, 4, 22)     0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 4, 4, 22)     4356        activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_49 (Dropout)            (None, 4, 4, 22)     0           conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_46 (Concatenate)    (None, 4, 4, 264)    0           concatenate_45[0][0]             \n",
      "                                                                 dropout_49[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 4, 4, 264)    1056        concatenate_46[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 4, 4, 264)    0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 4, 4, 22)     5808        activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 4, 4, 22)     88          conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 4, 4, 22)     0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 4, 4, 22)     4356        activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_50 (Dropout)            (None, 4, 4, 22)     0           conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_47 (Concatenate)    (None, 4, 4, 286)    0           concatenate_46[0][0]             \n",
      "                                                                 dropout_50[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 4, 4, 286)    1144        concatenate_47[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 4, 4, 286)    0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 2, 2, 286)    0           activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 1144)         0           average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           11450       flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 430,922\n",
      "Trainable params: 412,534\n",
      "Non-trainable params: 18,388\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model4 = Model(inputs = [input], outputs = [output])\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BJlYhiMu02N-",
    "outputId": "f8ed0a64-72dd-47f2-c595-9bef51403951"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "406\n"
     ]
    }
   ],
   "source": [
    "print(len(model4.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ufzxoneN02Lj",
    "outputId": "5715ed6a-a988-4082-97bc-963dd58184be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "781/781 [==============================] - 156s 147ms/step - loss: 1.8745 - accuracy: 0.3166 - val_loss: 1.5755 - val_accuracy: 0.4120\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.41200, saving model to model4_weights.best.hdf5\n",
      "Epoch 2/100\n",
      "781/781 [==============================] - 113s 144ms/step - loss: 1.5134 - accuracy: 0.4476 - val_loss: 2.1495 - val_accuracy: 0.3897\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.41200\n",
      "Epoch 3/100\n",
      "781/781 [==============================] - 113s 145ms/step - loss: 1.2878 - accuracy: 0.5322 - val_loss: 1.3345 - val_accuracy: 0.5544\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.41200 to 0.55440, saving model to model4_weights.best.hdf5\n",
      "Epoch 4/100\n",
      "781/781 [==============================] - 113s 144ms/step - loss: 1.1293 - accuracy: 0.5937 - val_loss: 1.5858 - val_accuracy: 0.5304\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.55440\n",
      "Epoch 5/100\n",
      "781/781 [==============================] - 112s 144ms/step - loss: 1.0299 - accuracy: 0.6319 - val_loss: 1.9975 - val_accuracy: 0.5153\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.55440\n",
      "Epoch 6/100\n",
      "781/781 [==============================] - 111s 142ms/step - loss: 0.9488 - accuracy: 0.6613 - val_loss: 1.9263 - val_accuracy: 0.5524\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.55440\n",
      "Epoch 7/100\n",
      "781/781 [==============================] - 113s 145ms/step - loss: 0.8844 - accuracy: 0.6872 - val_loss: 1.7518 - val_accuracy: 0.5706\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.55440 to 0.57060, saving model to model4_weights.best.hdf5\n",
      "Epoch 8/100\n",
      "781/781 [==============================] - 112s 144ms/step - loss: 0.8365 - accuracy: 0.7077 - val_loss: 1.0898 - val_accuracy: 0.6690\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.57060 to 0.66900, saving model to model4_weights.best.hdf5\n",
      "Epoch 9/100\n",
      "781/781 [==============================] - 112s 143ms/step - loss: 0.7971 - accuracy: 0.7210 - val_loss: 1.0606 - val_accuracy: 0.6947\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.66900 to 0.69470, saving model to model4_weights.best.hdf5\n",
      "Epoch 10/100\n",
      "781/781 [==============================] - 112s 143ms/step - loss: 0.7677 - accuracy: 0.7309 - val_loss: 1.2691 - val_accuracy: 0.6506\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.69470\n",
      "Epoch 11/100\n",
      "781/781 [==============================] - 111s 143ms/step - loss: 0.7344 - accuracy: 0.7426 - val_loss: 1.2606 - val_accuracy: 0.6762\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.69470\n",
      "Epoch 12/100\n",
      "781/781 [==============================] - 111s 142ms/step - loss: 0.6964 - accuracy: 0.7563 - val_loss: 1.0189 - val_accuracy: 0.7016\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.69470 to 0.70160, saving model to model4_weights.best.hdf5\n",
      "Epoch 13/100\n",
      "781/781 [==============================] - 111s 141ms/step - loss: 0.6829 - accuracy: 0.7622 - val_loss: 1.1461 - val_accuracy: 0.6758\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.70160\n",
      "Epoch 14/100\n",
      "781/781 [==============================] - 110s 141ms/step - loss: 0.6550 - accuracy: 0.7730 - val_loss: 0.6706 - val_accuracy: 0.7818\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.70160 to 0.78180, saving model to model4_weights.best.hdf5\n",
      "Epoch 15/100\n",
      "781/781 [==============================] - 111s 143ms/step - loss: 0.6381 - accuracy: 0.7790 - val_loss: 0.8606 - val_accuracy: 0.7516\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.78180\n",
      "Epoch 16/100\n",
      "781/781 [==============================] - 110s 141ms/step - loss: 0.6196 - accuracy: 0.7846 - val_loss: 0.7987 - val_accuracy: 0.7640\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.78180\n",
      "Epoch 17/100\n",
      "781/781 [==============================] - 111s 142ms/step - loss: 0.5988 - accuracy: 0.7919 - val_loss: 1.0603 - val_accuracy: 0.7108\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.78180\n",
      "Epoch 18/100\n",
      "781/781 [==============================] - 110s 141ms/step - loss: 0.5874 - accuracy: 0.7963 - val_loss: 0.7823 - val_accuracy: 0.7798\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.78180\n",
      "Epoch 19/100\n",
      "781/781 [==============================] - 110s 141ms/step - loss: 0.5753 - accuracy: 0.8027 - val_loss: 1.0639 - val_accuracy: 0.7091\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.78180\n",
      "Epoch 20/100\n",
      "781/781 [==============================] - 111s 142ms/step - loss: 0.5601 - accuracy: 0.8059 - val_loss: 0.8634 - val_accuracy: 0.7545\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.78180\n",
      "Epoch 21/100\n",
      "781/781 [==============================] - 110s 141ms/step - loss: 0.5575 - accuracy: 0.8075 - val_loss: 0.5594 - val_accuracy: 0.8232\n",
      "\n",
      "Epoch 00021: val_accuracy improved from 0.78180 to 0.82320, saving model to model4_weights.best.hdf5\n",
      "Epoch 22/100\n",
      "781/781 [==============================] - 110s 141ms/step - loss: 0.5381 - accuracy: 0.8136 - val_loss: 1.3817 - val_accuracy: 0.6963\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.82320\n",
      "Epoch 23/100\n",
      "781/781 [==============================] - 111s 143ms/step - loss: 0.5261 - accuracy: 0.8193 - val_loss: 0.7018 - val_accuracy: 0.7932\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.82320\n",
      "Epoch 24/100\n",
      "781/781 [==============================] - 111s 142ms/step - loss: 0.5167 - accuracy: 0.8212 - val_loss: 0.5503 - val_accuracy: 0.8296\n",
      "\n",
      "Epoch 00024: val_accuracy improved from 0.82320 to 0.82960, saving model to model4_weights.best.hdf5\n",
      "Epoch 25/100\n",
      "781/781 [==============================] - 111s 143ms/step - loss: 0.5086 - accuracy: 0.8253 - val_loss: 0.6031 - val_accuracy: 0.8230\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.82960\n",
      "Epoch 26/100\n",
      "781/781 [==============================] - 111s 142ms/step - loss: 0.4321 - accuracy: 0.8503 - val_loss: 0.5011 - val_accuracy: 0.8493\n",
      "\n",
      "Epoch 00026: val_accuracy improved from 0.82960 to 0.84930, saving model to model4_weights.best.hdf5\n",
      "Epoch 27/100\n",
      "781/781 [==============================] - 111s 142ms/step - loss: 0.4076 - accuracy: 0.8589 - val_loss: 0.5119 - val_accuracy: 0.8483\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.84930\n",
      "Epoch 28/100\n",
      "781/781 [==============================] - 111s 142ms/step - loss: 0.4057 - accuracy: 0.8594 - val_loss: 0.5179 - val_accuracy: 0.8472\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.84930\n",
      "Epoch 29/100\n",
      "781/781 [==============================] - 112s 143ms/step - loss: 0.3879 - accuracy: 0.8648 - val_loss: 0.4711 - val_accuracy: 0.8602\n",
      "\n",
      "Epoch 00029: val_accuracy improved from 0.84930 to 0.86020, saving model to model4_weights.best.hdf5\n",
      "Epoch 30/100\n",
      "781/781 [==============================] - 111s 142ms/step - loss: 0.3886 - accuracy: 0.8649 - val_loss: 0.5071 - val_accuracy: 0.8506\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.86020\n",
      "Epoch 31/100\n",
      "781/781 [==============================] - 112s 144ms/step - loss: 0.3812 - accuracy: 0.8668 - val_loss: 0.4773 - val_accuracy: 0.8555\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.86020\n",
      "Epoch 32/100\n",
      "781/781 [==============================] - 112s 143ms/step - loss: 0.3778 - accuracy: 0.8697 - val_loss: 0.4644 - val_accuracy: 0.8615\n",
      "\n",
      "Epoch 00032: val_accuracy improved from 0.86020 to 0.86150, saving model to model4_weights.best.hdf5\n",
      "Epoch 33/100\n",
      "781/781 [==============================] - 113s 144ms/step - loss: 0.3708 - accuracy: 0.8713 - val_loss: 0.4852 - val_accuracy: 0.8567\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.86150\n",
      "Epoch 34/100\n",
      "781/781 [==============================] - 112s 143ms/step - loss: 0.3701 - accuracy: 0.8716 - val_loss: 0.4682 - val_accuracy: 0.8628\n",
      "\n",
      "Epoch 00034: val_accuracy improved from 0.86150 to 0.86280, saving model to model4_weights.best.hdf5\n",
      "Epoch 35/100\n",
      "781/781 [==============================] - 112s 143ms/step - loss: 0.3693 - accuracy: 0.8707 - val_loss: 0.4320 - val_accuracy: 0.8683\n",
      "\n",
      "Epoch 00035: val_accuracy improved from 0.86280 to 0.86830, saving model to model4_weights.best.hdf5\n",
      "Epoch 36/100\n",
      "781/781 [==============================] - 113s 144ms/step - loss: 0.3677 - accuracy: 0.8723 - val_loss: 0.4543 - val_accuracy: 0.8612\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.86830\n",
      "Epoch 37/100\n",
      "781/781 [==============================] - 111s 142ms/step - loss: 0.3629 - accuracy: 0.8740 - val_loss: 0.4707 - val_accuracy: 0.8607\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.86830\n",
      "Epoch 38/100\n",
      "781/781 [==============================] - 111s 142ms/step - loss: 0.3639 - accuracy: 0.8720 - val_loss: 0.4179 - val_accuracy: 0.8723\n",
      "\n",
      "Epoch 00038: val_accuracy improved from 0.86830 to 0.87230, saving model to model4_weights.best.hdf5\n",
      "Epoch 39/100\n",
      "781/781 [==============================] - 111s 142ms/step - loss: 0.3587 - accuracy: 0.8753 - val_loss: 0.4980 - val_accuracy: 0.8545\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.87230\n",
      "Epoch 40/100\n",
      "781/781 [==============================] - 111s 142ms/step - loss: 0.3590 - accuracy: 0.8754 - val_loss: 0.4487 - val_accuracy: 0.8654\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.87230\n",
      "Epoch 41/100\n",
      "781/781 [==============================] - 112s 143ms/step - loss: 0.3584 - accuracy: 0.8753 - val_loss: 0.4502 - val_accuracy: 0.8675\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.87230\n",
      "Epoch 42/100\n",
      "781/781 [==============================] - 112s 143ms/step - loss: 0.3542 - accuracy: 0.8765 - val_loss: 0.4410 - val_accuracy: 0.8695\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.87230\n",
      "Epoch 43/100\n",
      "781/781 [==============================] - 112s 143ms/step - loss: 0.3493 - accuracy: 0.8794 - val_loss: 0.4599 - val_accuracy: 0.8645\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.87230\n",
      "Epoch 44/100\n",
      "781/781 [==============================] - 112s 143ms/step - loss: 0.3514 - accuracy: 0.8775 - val_loss: 0.4182 - val_accuracy: 0.8739\n",
      "\n",
      "Epoch 00044: val_accuracy improved from 0.87230 to 0.87390, saving model to model4_weights.best.hdf5\n",
      "Epoch 45/100\n",
      "781/781 [==============================] - 111s 142ms/step - loss: 0.3435 - accuracy: 0.8812 - val_loss: 0.4750 - val_accuracy: 0.8621\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.87390\n",
      "Epoch 46/100\n",
      "781/781 [==============================] - 112s 143ms/step - loss: 0.3432 - accuracy: 0.8806 - val_loss: 0.4735 - val_accuracy: 0.8647\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.87390\n",
      "Epoch 47/100\n",
      "781/781 [==============================] - 112s 144ms/step - loss: 0.3459 - accuracy: 0.8795 - val_loss: 0.4101 - val_accuracy: 0.8783\n",
      "\n",
      "Epoch 00047: val_accuracy improved from 0.87390 to 0.87830, saving model to model4_weights.best.hdf5\n",
      "Epoch 48/100\n",
      "781/781 [==============================] - 112s 143ms/step - loss: 0.3429 - accuracy: 0.8806 - val_loss: 0.4195 - val_accuracy: 0.8758\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.87830\n",
      "Epoch 49/100\n",
      "781/781 [==============================] - 111s 143ms/step - loss: 0.3411 - accuracy: 0.8811 - val_loss: 0.4149 - val_accuracy: 0.8765\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.87830\n",
      "Epoch 50/100\n",
      "781/781 [==============================] - 111s 143ms/step - loss: 0.3400 - accuracy: 0.8812 - val_loss: 0.4378 - val_accuracy: 0.8727\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.87830\n",
      "Epoch 51/100\n",
      "781/781 [==============================] - 112s 144ms/step - loss: 0.3305 - accuracy: 0.8839 - val_loss: 0.4342 - val_accuracy: 0.8747\n",
      "\n",
      "Epoch 00051: val_accuracy did not improve from 0.87830\n",
      "Epoch 52/100\n",
      "781/781 [==============================] - 112s 143ms/step - loss: 0.3309 - accuracy: 0.8839 - val_loss: 0.4376 - val_accuracy: 0.8740\n",
      "\n",
      "Epoch 00052: val_accuracy did not improve from 0.87830\n",
      "Epoch 53/100\n",
      "781/781 [==============================] - 112s 143ms/step - loss: 0.3282 - accuracy: 0.8860 - val_loss: 0.4272 - val_accuracy: 0.8764\n",
      "\n",
      "Epoch 00053: val_accuracy did not improve from 0.87830\n",
      "Epoch 54/100\n",
      "781/781 [==============================] - 112s 143ms/step - loss: 0.3270 - accuracy: 0.8854 - val_loss: 0.4354 - val_accuracy: 0.8747\n",
      "\n",
      "Epoch 00054: val_accuracy did not improve from 0.87830\n",
      "Epoch 55/100\n",
      "781/781 [==============================] - 112s 144ms/step - loss: 0.3290 - accuracy: 0.8861 - val_loss: 0.4283 - val_accuracy: 0.8758\n",
      "\n",
      "Epoch 00055: val_accuracy did not improve from 0.87830\n",
      "Epoch 56/100\n",
      "781/781 [==============================] - 113s 144ms/step - loss: 0.3254 - accuracy: 0.8854 - val_loss: 0.4209 - val_accuracy: 0.8769\n",
      "\n",
      "Epoch 00056: val_accuracy did not improve from 0.87830\n",
      "Epoch 57/100\n",
      "781/781 [==============================] - 113s 144ms/step - loss: 0.3272 - accuracy: 0.8857 - val_loss: 0.4203 - val_accuracy: 0.8762\n",
      "\n",
      "Epoch 00057: val_accuracy did not improve from 0.87830\n",
      "Epoch 58/100\n",
      "781/781 [==============================] - 113s 144ms/step - loss: 0.3252 - accuracy: 0.8862 - val_loss: 0.4251 - val_accuracy: 0.8750\n",
      "\n",
      "Epoch 00058: val_accuracy did not improve from 0.87830\n",
      "Epoch 59/100\n",
      "781/781 [==============================] - 112s 144ms/step - loss: 0.3272 - accuracy: 0.8863 - val_loss: 0.4227 - val_accuracy: 0.8766\n",
      "\n",
      "Epoch 00059: val_accuracy did not improve from 0.87830\n",
      "Epoch 60/100\n",
      "781/781 [==============================] - 112s 143ms/step - loss: 0.3245 - accuracy: 0.8865 - val_loss: 0.4110 - val_accuracy: 0.8793\n",
      "\n",
      "Epoch 00060: val_accuracy improved from 0.87830 to 0.87930, saving model to model4_weights.best.hdf5\n",
      "Epoch 61/100\n",
      "781/781 [==============================] - 112s 143ms/step - loss: 0.3223 - accuracy: 0.8853 - val_loss: 0.4218 - val_accuracy: 0.8763\n",
      "\n",
      "Epoch 00061: val_accuracy did not improve from 0.87930\n",
      "Epoch 62/100\n",
      "781/781 [==============================] - 112s 143ms/step - loss: 0.3241 - accuracy: 0.8875 - val_loss: 0.4214 - val_accuracy: 0.8776\n",
      "\n",
      "Epoch 00062: val_accuracy did not improve from 0.87930\n",
      "Epoch 63/100\n",
      "781/781 [==============================] - 113s 144ms/step - loss: 0.3159 - accuracy: 0.8897 - val_loss: 0.4203 - val_accuracy: 0.8772\n",
      "\n",
      "Epoch 00063: val_accuracy did not improve from 0.87930\n",
      "Epoch 64/100\n",
      "781/781 [==============================] - 113s 144ms/step - loss: 0.3170 - accuracy: 0.8894 - val_loss: 0.4326 - val_accuracy: 0.8756\n",
      "\n",
      "Epoch 00064: val_accuracy did not improve from 0.87930\n",
      "Epoch 65/100\n",
      "781/781 [==============================] - 112s 143ms/step - loss: 0.3238 - accuracy: 0.8863 - val_loss: 0.4230 - val_accuracy: 0.8780\n",
      "\n",
      "Epoch 00065: val_accuracy did not improve from 0.87930\n",
      "Epoch 66/100\n",
      "781/781 [==============================] - 112s 144ms/step - loss: 0.3202 - accuracy: 0.8885 - val_loss: 0.4199 - val_accuracy: 0.8773\n",
      "\n",
      "Epoch 00066: val_accuracy did not improve from 0.87930\n",
      "Epoch 67/100\n",
      "781/781 [==============================] - 113s 145ms/step - loss: 0.3236 - accuracy: 0.8879 - val_loss: 0.4251 - val_accuracy: 0.8763\n",
      "\n",
      "Epoch 00067: val_accuracy did not improve from 0.87930\n",
      "Epoch 68/100\n",
      "781/781 [==============================] - 112s 143ms/step - loss: 0.3223 - accuracy: 0.8871 - val_loss: 0.4196 - val_accuracy: 0.8784\n",
      "\n",
      "Epoch 00068: val_accuracy did not improve from 0.87930\n",
      "Epoch 69/100\n",
      "781/781 [==============================] - 112s 143ms/step - loss: 0.3236 - accuracy: 0.8870 - val_loss: 0.4162 - val_accuracy: 0.8787\n",
      "\n",
      "Epoch 00069: val_accuracy did not improve from 0.87930\n",
      "Epoch 70/100\n",
      "781/781 [==============================] - 112s 143ms/step - loss: 0.3185 - accuracy: 0.8889 - val_loss: 0.4195 - val_accuracy: 0.8776\n",
      "\n",
      "Epoch 00070: val_accuracy did not improve from 0.87930\n",
      "Epoch 71/100\n",
      "781/781 [==============================] - 111s 143ms/step - loss: 0.3236 - accuracy: 0.8878 - val_loss: 0.4258 - val_accuracy: 0.8761\n",
      "\n",
      "Epoch 00071: val_accuracy did not improve from 0.87930\n",
      "Epoch 72/100\n",
      "781/781 [==============================] - 113s 144ms/step - loss: 0.3148 - accuracy: 0.8906 - val_loss: 0.4257 - val_accuracy: 0.8770\n",
      "\n",
      "Epoch 00072: val_accuracy did not improve from 0.87930\n",
      "Epoch 73/100\n",
      "781/781 [==============================] - 113s 145ms/step - loss: 0.3217 - accuracy: 0.8883 - val_loss: 0.4205 - val_accuracy: 0.8779\n",
      "\n",
      "Epoch 00073: val_accuracy did not improve from 0.87930\n",
      "Epoch 74/100\n",
      "781/781 [==============================] - 114s 146ms/step - loss: 0.3227 - accuracy: 0.8872 - val_loss: 0.4192 - val_accuracy: 0.8773\n",
      "\n",
      "Epoch 00074: val_accuracy did not improve from 0.87930\n",
      "Epoch 75/100\n",
      "781/781 [==============================] - 113s 144ms/step - loss: 0.3201 - accuracy: 0.8880 - val_loss: 0.4136 - val_accuracy: 0.8799\n",
      "\n",
      "Epoch 00075: val_accuracy improved from 0.87930 to 0.87990, saving model to model4_weights.best.hdf5\n",
      "Epoch 76/100\n",
      "781/781 [==============================] - 113s 144ms/step - loss: 0.3209 - accuracy: 0.8875 - val_loss: 0.4124 - val_accuracy: 0.8793\n",
      "\n",
      "Epoch 00076: val_accuracy did not improve from 0.87990\n",
      "Epoch 77/100\n",
      "781/781 [==============================] - 113s 145ms/step - loss: 0.3179 - accuracy: 0.8881 - val_loss: 0.4118 - val_accuracy: 0.8793\n",
      "\n",
      "Epoch 00077: val_accuracy did not improve from 0.87990\n",
      "Epoch 78/100\n",
      "781/781 [==============================] - 112s 143ms/step - loss: 0.3236 - accuracy: 0.8860 - val_loss: 0.4153 - val_accuracy: 0.8780\n",
      "\n",
      "Epoch 00078: val_accuracy did not improve from 0.87990\n",
      "Epoch 79/100\n",
      "781/781 [==============================] - 113s 144ms/step - loss: 0.3209 - accuracy: 0.8888 - val_loss: 0.4224 - val_accuracy: 0.8780\n",
      "\n",
      "Epoch 00079: val_accuracy did not improve from 0.87990\n",
      "Epoch 80/100\n",
      "781/781 [==============================] - 112s 143ms/step - loss: 0.3206 - accuracy: 0.8882 - val_loss: 0.4182 - val_accuracy: 0.8777\n",
      "\n",
      "Epoch 00080: val_accuracy did not improve from 0.87990\n",
      "Epoch 81/100\n",
      "781/781 [==============================] - 112s 144ms/step - loss: 0.3177 - accuracy: 0.8892 - val_loss: 0.4137 - val_accuracy: 0.8793\n",
      "\n",
      "Epoch 00081: val_accuracy did not improve from 0.87990\n",
      "Epoch 82/100\n",
      "781/781 [==============================] - 112s 143ms/step - loss: 0.3198 - accuracy: 0.8883 - val_loss: 0.4240 - val_accuracy: 0.8772\n",
      "\n",
      "Epoch 00082: val_accuracy did not improve from 0.87990\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f01140b5b90>"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model4.fit(aug.flow(X_train,y_train,batch_size=batch_size),epochs=nb_epoch,batch_size=batch_size,verbose=1,\n",
    "           steps_per_epoch=(len(X_train)//batch_size),\n",
    "           callbacks=[reduce_lr,lr_scheduler,csv_logger,early_stop,model_checkpoint],\n",
    "           validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H-rgEuzuUyys"
   },
   "source": [
    "### 2.6 Growth Rate(num_filter) = 36, compression = 0.7, Number of blocks = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t3iDbjm6eUPY"
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 64\n",
    "num_classes = 10\n",
    "nb_epoch = 100\n",
    "l = 12\n",
    "num_filter = 36\n",
    "compression = 0.7\n",
    "dropout_rate = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HtDx7H8neUMe"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "#https://machinelearningmastery.com/check-point-deep-learning-models-keras/\n",
    "filepath=\"model5_weights.best.hdf5\"\n",
    "model_checkpoint = ModelCheckpoint(filepath,monitor='val_accuracy',save_best_only=True,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tRIJCtRAeUJi"
   },
   "outputs": [],
   "source": [
    "input = layers.Input(shape=(img_height, img_width, channel,))\n",
    "First_Conv2D = layers.Conv2D(num_filter, (3,3), use_bias=False ,padding='same')(input)\n",
    "\n",
    "First_Block = denseblock(First_Conv2D, num_filter, dropout_rate)\n",
    "First_Transition = transition(First_Block, num_filter, dropout_rate)\n",
    "\n",
    "Second_Block = denseblock(First_Transition, num_filter, dropout_rate)\n",
    "Second_Transition = transition(Second_Block, num_filter, dropout_rate)\n",
    "\n",
    "Third_Block = denseblock(Second_Transition, num_filter, dropout_rate)\n",
    "Third_Transition = transition(Third_Block, num_filter, dropout_rate)\n",
    "\n",
    "Last_Block = denseblock(Third_Transition,  num_filter, dropout_rate)\n",
    "output = output_layer(Last_Block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-l-Rrz_neUGB",
    "outputId": "67e61f6b-73d2-4d6d-e772-74088e7edc34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 32, 32, 36)   972         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 32, 32, 36)   144         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 32, 32, 36)   0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 32, 32, 25)   900         activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 32, 25)   100         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 32, 32, 25)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 25)   5625        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 32, 32, 25)   0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 32, 32, 61)   0           conv2d[0][0]                     \n",
      "                                                                 dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 61)   244         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 32, 32, 61)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 32, 25)   1525        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 32, 25)   100         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 32, 32, 25)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 32, 32, 25)   5625        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 32, 32, 25)   0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 32, 32, 86)   0           concatenate[0][0]                \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 32, 32, 86)   344         concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 32, 32, 86)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 32, 32, 25)   2150        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32, 32, 25)   100         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 32, 32, 25)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 25)   5625        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 32, 32, 25)   0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 32, 32, 111)  0           concatenate_1[0][0]              \n",
      "                                                                 dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 32, 32, 111)  444         concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 32, 32, 111)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 25)   2775        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 32, 32, 25)   100         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 32, 32, 25)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 25)   5625        activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 32, 32, 25)   0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 32, 32, 136)  0           concatenate_2[0][0]              \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 32, 136)  544         concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 32, 32, 136)  0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 25)   3400        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 32, 32, 25)   100         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 32, 32, 25)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 32, 32, 25)   5625        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 32, 32, 25)   0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 32, 32, 161)  0           concatenate_3[0][0]              \n",
      "                                                                 dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 32, 32, 161)  644         concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 32, 32, 161)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 32, 32, 25)   4025        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 32, 32, 25)   100         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 32, 32, 25)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 32, 32, 25)   5625        activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 32, 32, 25)   0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 32, 32, 186)  0           concatenate_4[0][0]              \n",
      "                                                                 dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 32, 32, 186)  744         concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 32, 32, 186)  0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 32, 32, 25)   4650        activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 32, 32, 25)   100         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 32, 32, 25)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 32, 32, 25)   5625        activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 32, 32, 25)   0           conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 32, 32, 211)  0           concatenate_5[0][0]              \n",
      "                                                                 dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 32, 32, 211)  844         concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 32, 32, 211)  0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 32, 32, 25)   5275        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 32, 32, 25)   100         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 32, 32, 25)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 32, 32, 25)   5625        activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 32, 32, 25)   0           conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 32, 32, 236)  0           concatenate_6[0][0]              \n",
      "                                                                 dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 32, 32, 236)  944         concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 32, 32, 236)  0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 32, 32, 25)   5900        activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 32, 32, 25)   100         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 32, 32, 25)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 32, 32, 25)   5625        activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 32, 32, 25)   0           conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 32, 32, 261)  0           concatenate_7[0][0]              \n",
      "                                                                 dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 32, 32, 261)  1044        concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 32, 32, 261)  0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 32, 32, 25)   6525        activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 32, 32, 25)   100         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 32, 32, 25)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 32, 32, 25)   5625        activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 32, 32, 25)   0           conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 32, 32, 286)  0           concatenate_8[0][0]              \n",
      "                                                                 dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 32, 32, 286)  1144        concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 32, 32, 286)  0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 32, 32, 25)   7150        activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 32, 32, 25)   100         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 32, 32, 25)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 32, 32, 25)   5625        activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 32, 32, 25)   0           conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 32, 32, 311)  0           concatenate_9[0][0]              \n",
      "                                                                 dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 32, 32, 311)  1244        concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 32, 32, 311)  0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 32, 32, 25)   7775        activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 32, 32, 25)   100         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 32, 32, 25)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 32, 32, 25)   5625        activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 32, 32, 25)   0           conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 32, 32, 336)  0           concatenate_10[0][0]             \n",
      "                                                                 dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 32, 32, 336)  1344        concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 32, 32, 336)  0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 32, 32, 25)   8400        activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 32, 32, 25)   0           conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 16, 16, 25)   0           dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 16, 16, 25)   100         average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 16, 16, 25)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 16, 16, 25)   625         activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 16, 16, 25)   100         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 16, 16, 25)   0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 16, 16, 25)   5625        activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 16, 16, 25)   0           conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 16, 16, 50)   0           average_pooling2d[0][0]          \n",
      "                                                                 dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 16, 16, 50)   200         concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 16, 16, 50)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 16, 16, 25)   1250        activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 16, 16, 25)   100         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 16, 16, 25)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 16, 16, 25)   5625        activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 16, 16, 25)   0           conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 16, 16, 75)   0           concatenate_12[0][0]             \n",
      "                                                                 dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 16, 16, 75)   300         concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 16, 16, 75)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 16, 16, 25)   1875        activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 16, 16, 25)   100         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 16, 16, 25)   0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 16, 16, 25)   5625        activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 16, 16, 25)   0           conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 16, 16, 100)  0           concatenate_13[0][0]             \n",
      "                                                                 dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 16, 16, 100)  400         concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 16, 16, 100)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 16, 16, 25)   2500        activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 16, 16, 25)   100         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 16, 16, 25)   0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 16, 16, 25)   5625        activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 16, 16, 25)   0           conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 16, 16, 125)  0           concatenate_14[0][0]             \n",
      "                                                                 dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 16, 16, 125)  500         concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 16, 16, 125)  0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 16, 16, 25)   3125        activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 16, 16, 25)   100         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 16, 16, 25)   0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 16, 16, 25)   5625        activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 16, 16, 25)   0           conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 16, 16, 150)  0           concatenate_15[0][0]             \n",
      "                                                                 dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 16, 16, 150)  600         concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 16, 16, 150)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 16, 16, 25)   3750        activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 16, 16, 25)   100         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 16, 16, 25)   0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 16, 16, 25)   5625        activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 16, 16, 25)   0           conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, 16, 16, 175)  0           concatenate_16[0][0]             \n",
      "                                                                 dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 16, 16, 175)  700         concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 16, 16, 175)  0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 16, 16, 25)   4375        activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 16, 16, 25)   100         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 16, 16, 25)   0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 16, 16, 25)   5625        activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 16, 16, 25)   0           conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, 16, 16, 200)  0           concatenate_17[0][0]             \n",
      "                                                                 dropout_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 16, 16, 200)  800         concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 16, 16, 200)  0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 16, 16, 25)   5000        activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 16, 16, 25)   100         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 16, 16, 25)   0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 16, 16, 25)   5625        activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 16, 16, 25)   0           conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, 16, 16, 225)  0           concatenate_18[0][0]             \n",
      "                                                                 dropout_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 16, 16, 225)  900         concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 16, 16, 225)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 16, 16, 25)   5625        activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 16, 16, 25)   100         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 16, 16, 25)   0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 16, 16, 25)   5625        activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 16, 16, 25)   0           conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_20 (Concatenate)    (None, 16, 16, 250)  0           concatenate_19[0][0]             \n",
      "                                                                 dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 16, 16, 250)  1000        concatenate_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 16, 16, 250)  0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 16, 16, 25)   6250        activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 16, 16, 25)   100         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 16, 16, 25)   0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 16, 16, 25)   5625        activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 16, 16, 25)   0           conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_21 (Concatenate)    (None, 16, 16, 275)  0           concatenate_20[0][0]             \n",
      "                                                                 dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 16, 16, 275)  1100        concatenate_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 16, 16, 275)  0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 16, 16, 25)   6875        activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 16, 16, 25)   100         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 16, 16, 25)   0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 16, 16, 25)   5625        activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 16, 16, 25)   0           conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_22 (Concatenate)    (None, 16, 16, 300)  0           concatenate_21[0][0]             \n",
      "                                                                 dropout_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 16, 16, 300)  1200        concatenate_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 16, 16, 300)  0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 16, 16, 25)   7500        activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 16, 16, 25)   100         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 16, 16, 25)   0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 16, 16, 25)   5625        activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 16, 16, 25)   0           conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_23 (Concatenate)    (None, 16, 16, 325)  0           concatenate_22[0][0]             \n",
      "                                                                 dropout_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 16, 16, 325)  1300        concatenate_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 16, 16, 325)  0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 16, 16, 25)   8125        activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, 16, 16, 25)   0           conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 8, 8, 25)     0           dropout_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 8, 8, 25)     100         average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 8, 8, 25)     0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 8, 8, 25)     625         activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 8, 8, 25)     100         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 8, 8, 25)     0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 8, 8, 25)     5625        activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)            (None, 8, 8, 25)     0           conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_24 (Concatenate)    (None, 8, 8, 50)     0           average_pooling2d_1[0][0]        \n",
      "                                                                 dropout_26[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 8, 8, 50)     200         concatenate_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 8, 8, 50)     0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 8, 8, 25)     1250        activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 8, 8, 25)     100         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 8, 8, 25)     0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 8, 8, 25)     5625        activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)            (None, 8, 8, 25)     0           conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_25 (Concatenate)    (None, 8, 8, 75)     0           concatenate_24[0][0]             \n",
      "                                                                 dropout_27[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 8, 8, 75)     300         concatenate_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 8, 8, 75)     0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 8, 8, 25)     1875        activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 8, 8, 25)     100         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 8, 8, 25)     0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 8, 8, 25)     5625        activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_28 (Dropout)            (None, 8, 8, 25)     0           conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_26 (Concatenate)    (None, 8, 8, 100)    0           concatenate_25[0][0]             \n",
      "                                                                 dropout_28[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 8, 8, 100)    400         concatenate_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 8, 8, 100)    0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 8, 8, 25)     2500        activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 8, 8, 25)     100         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 8, 8, 25)     0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 8, 8, 25)     5625        activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_29 (Dropout)            (None, 8, 8, 25)     0           conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_27 (Concatenate)    (None, 8, 8, 125)    0           concatenate_26[0][0]             \n",
      "                                                                 dropout_29[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 8, 8, 125)    500         concatenate_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 8, 8, 125)    0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 8, 8, 25)     3125        activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 8, 8, 25)     100         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 8, 8, 25)     0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 8, 8, 25)     5625        activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_30 (Dropout)            (None, 8, 8, 25)     0           conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_28 (Concatenate)    (None, 8, 8, 150)    0           concatenate_27[0][0]             \n",
      "                                                                 dropout_30[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 8, 8, 150)    600         concatenate_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 8, 8, 150)    0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 8, 8, 25)     3750        activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 8, 8, 25)     100         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 8, 8, 25)     0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 8, 8, 25)     5625        activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_31 (Dropout)            (None, 8, 8, 25)     0           conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_29 (Concatenate)    (None, 8, 8, 175)    0           concatenate_28[0][0]             \n",
      "                                                                 dropout_31[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 8, 8, 175)    700         concatenate_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 8, 8, 175)    0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 8, 8, 25)     4375        activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 8, 8, 25)     100         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 8, 8, 25)     0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 8, 8, 25)     5625        activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_32 (Dropout)            (None, 8, 8, 25)     0           conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_30 (Concatenate)    (None, 8, 8, 200)    0           concatenate_29[0][0]             \n",
      "                                                                 dropout_32[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 8, 8, 200)    800         concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 8, 8, 200)    0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 8, 8, 25)     5000        activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 8, 8, 25)     100         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 8, 8, 25)     0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 8, 8, 25)     5625        activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_33 (Dropout)            (None, 8, 8, 25)     0           conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_31 (Concatenate)    (None, 8, 8, 225)    0           concatenate_30[0][0]             \n",
      "                                                                 dropout_33[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 8, 8, 225)    900         concatenate_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 8, 8, 225)    0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 8, 8, 25)     5625        activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 8, 8, 25)     100         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 8, 8, 25)     0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 8, 8, 25)     5625        activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_34 (Dropout)            (None, 8, 8, 25)     0           conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_32 (Concatenate)    (None, 8, 8, 250)    0           concatenate_31[0][0]             \n",
      "                                                                 dropout_34[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 8, 8, 250)    1000        concatenate_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 8, 8, 250)    0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 8, 8, 25)     6250        activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 8, 8, 25)     100         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 8, 8, 25)     0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 8, 8, 25)     5625        activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_35 (Dropout)            (None, 8, 8, 25)     0           conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_33 (Concatenate)    (None, 8, 8, 275)    0           concatenate_32[0][0]             \n",
      "                                                                 dropout_35[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 8, 8, 275)    1100        concatenate_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 8, 8, 275)    0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 8, 8, 25)     6875        activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 8, 8, 25)     100         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 8, 8, 25)     0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 8, 8, 25)     5625        activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_36 (Dropout)            (None, 8, 8, 25)     0           conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_34 (Concatenate)    (None, 8, 8, 300)    0           concatenate_33[0][0]             \n",
      "                                                                 dropout_36[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 8, 8, 300)    1200        concatenate_34[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 8, 8, 300)    0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 8, 8, 25)     7500        activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 8, 8, 25)     100         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 8, 8, 25)     0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 8, 8, 25)     5625        activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, 8, 8, 25)     0           conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_35 (Concatenate)    (None, 8, 8, 325)    0           concatenate_34[0][0]             \n",
      "                                                                 dropout_37[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 8, 8, 325)    1300        concatenate_35[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 8, 8, 325)    0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 8, 8, 25)     8125        activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_38 (Dropout)            (None, 8, 8, 25)     0           conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 4, 4, 25)     0           dropout_38[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 4, 4, 25)     100         average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 4, 4, 25)     0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 4, 4, 25)     625         activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 4, 4, 25)     100         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 4, 4, 25)     0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 4, 4, 25)     5625        activation_76[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_39 (Dropout)            (None, 4, 4, 25)     0           conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_36 (Concatenate)    (None, 4, 4, 50)     0           average_pooling2d_2[0][0]        \n",
      "                                                                 dropout_39[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 4, 4, 50)     200         concatenate_36[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 4, 4, 50)     0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 4, 4, 25)     1250        activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 4, 4, 25)     100         conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 4, 4, 25)     0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 4, 4, 25)     5625        activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_40 (Dropout)            (None, 4, 4, 25)     0           conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_37 (Concatenate)    (None, 4, 4, 75)     0           concatenate_36[0][0]             \n",
      "                                                                 dropout_40[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 4, 4, 75)     300         concatenate_37[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 4, 4, 75)     0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 4, 4, 25)     1875        activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 4, 4, 25)     100         conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 4, 4, 25)     0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 4, 4, 25)     5625        activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_41 (Dropout)            (None, 4, 4, 25)     0           conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_38 (Concatenate)    (None, 4, 4, 100)    0           concatenate_37[0][0]             \n",
      "                                                                 dropout_41[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 4, 4, 100)    400         concatenate_38[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 4, 4, 100)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 4, 4, 25)     2500        activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 4, 4, 25)     100         conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 4, 4, 25)     0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 4, 4, 25)     5625        activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_42 (Dropout)            (None, 4, 4, 25)     0           conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_39 (Concatenate)    (None, 4, 4, 125)    0           concatenate_38[0][0]             \n",
      "                                                                 dropout_42[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 4, 4, 125)    500         concatenate_39[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 4, 4, 125)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 4, 4, 25)     3125        activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 4, 4, 25)     100         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 4, 4, 25)     0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 4, 4, 25)     5625        activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_43 (Dropout)            (None, 4, 4, 25)     0           conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_40 (Concatenate)    (None, 4, 4, 150)    0           concatenate_39[0][0]             \n",
      "                                                                 dropout_43[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 4, 4, 150)    600         concatenate_40[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 4, 4, 150)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 4, 4, 25)     3750        activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 4, 4, 25)     100         conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 4, 4, 25)     0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 4, 4, 25)     5625        activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_44 (Dropout)            (None, 4, 4, 25)     0           conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_41 (Concatenate)    (None, 4, 4, 175)    0           concatenate_40[0][0]             \n",
      "                                                                 dropout_44[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 4, 4, 175)    700         concatenate_41[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 4, 4, 175)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 4, 4, 25)     4375        activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 4, 4, 25)     100         conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 4, 4, 25)     0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 4, 4, 25)     5625        activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_45 (Dropout)            (None, 4, 4, 25)     0           conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_42 (Concatenate)    (None, 4, 4, 200)    0           concatenate_41[0][0]             \n",
      "                                                                 dropout_45[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 4, 4, 200)    800         concatenate_42[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 4, 4, 200)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 4, 4, 25)     5000        activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 4, 4, 25)     100         conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 4, 4, 25)     0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 4, 4, 25)     5625        activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_46 (Dropout)            (None, 4, 4, 25)     0           conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_43 (Concatenate)    (None, 4, 4, 225)    0           concatenate_42[0][0]             \n",
      "                                                                 dropout_46[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 4, 4, 225)    900         concatenate_43[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 4, 4, 225)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 4, 4, 25)     5625        activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 4, 4, 25)     100         conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 4, 4, 25)     0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 4, 4, 25)     5625        activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_47 (Dropout)            (None, 4, 4, 25)     0           conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_44 (Concatenate)    (None, 4, 4, 250)    0           concatenate_43[0][0]             \n",
      "                                                                 dropout_47[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 4, 4, 250)    1000        concatenate_44[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 4, 4, 250)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 4, 4, 25)     6250        activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 4, 4, 25)     100         conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 4, 4, 25)     0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 4, 4, 25)     5625        activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_48 (Dropout)            (None, 4, 4, 25)     0           conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_45 (Concatenate)    (None, 4, 4, 275)    0           concatenate_44[0][0]             \n",
      "                                                                 dropout_48[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 4, 4, 275)    1100        concatenate_45[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 4, 4, 275)    0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 4, 4, 25)     6875        activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 4, 4, 25)     100         conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 4, 4, 25)     0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 4, 4, 25)     5625        activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_49 (Dropout)            (None, 4, 4, 25)     0           conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_46 (Concatenate)    (None, 4, 4, 300)    0           concatenate_45[0][0]             \n",
      "                                                                 dropout_49[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 4, 4, 300)    1200        concatenate_46[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 4, 4, 300)    0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 4, 4, 25)     7500        activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 4, 4, 25)     100         conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 4, 4, 25)     0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 4, 4, 25)     5625        activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_50 (Dropout)            (None, 4, 4, 25)     0           conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_47 (Concatenate)    (None, 4, 4, 325)    0           concatenate_46[0][0]             \n",
      "                                                                 dropout_50[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 4, 4, 325)    1300        concatenate_47[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 4, 4, 325)    0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 2, 2, 325)    0           activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 1300)         0           average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           13010       flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 548,704\n",
      "Trainable params: 527,818\n",
      "Non-trainable params: 20,886\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model5 = Model(inputs = [input], outputs = [output])\n",
    "model5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YcgCJpHSeUEU",
    "outputId": "1bf75438-2505-4d60-fb81-fa3b5b54af5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "406\n"
     ]
    }
   ],
   "source": [
    "print(len(model5.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ephpZeGseUAf",
    "outputId": "8ecbf227-d2ee-4aab-c7b9-9d796e48e3c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "781/781 [==============================] - 168s 163ms/step - loss: 1.9539 - accuracy: 0.2869 - val_loss: 1.8601 - val_accuracy: 0.3451\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.34510, saving model to model5_weights.best.hdf5\n",
      "Epoch 2/100\n",
      "781/781 [==============================] - 125s 161ms/step - loss: 1.5744 - accuracy: 0.4215 - val_loss: 2.7340 - val_accuracy: 0.2778\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.34510\n",
      "Epoch 3/100\n",
      "781/781 [==============================] - 126s 161ms/step - loss: 1.3330 - accuracy: 0.5172 - val_loss: 2.8528 - val_accuracy: 0.3612\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.34510 to 0.36120, saving model to model5_weights.best.hdf5\n",
      "Epoch 4/100\n",
      "781/781 [==============================] - 126s 161ms/step - loss: 1.1693 - accuracy: 0.5798 - val_loss: 1.3349 - val_accuracy: 0.5871\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.36120 to 0.58710, saving model to model5_weights.best.hdf5\n",
      "Epoch 5/100\n",
      "781/781 [==============================] - 126s 161ms/step - loss: 1.0555 - accuracy: 0.6220 - val_loss: 1.4948 - val_accuracy: 0.5794\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.58710\n",
      "Epoch 6/100\n",
      "781/781 [==============================] - 125s 160ms/step - loss: 0.9628 - accuracy: 0.6577 - val_loss: 3.3519 - val_accuracy: 0.3629\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.58710\n",
      "Epoch 7/100\n",
      "781/781 [==============================] - 125s 160ms/step - loss: 0.8920 - accuracy: 0.6870 - val_loss: 1.3352 - val_accuracy: 0.6218\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.58710 to 0.62180, saving model to model5_weights.best.hdf5\n",
      "Epoch 8/100\n",
      "781/781 [==============================] - 125s 160ms/step - loss: 0.8268 - accuracy: 0.7100 - val_loss: 1.1063 - val_accuracy: 0.6978\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.62180 to 0.69780, saving model to model5_weights.best.hdf5\n",
      "Epoch 9/100\n",
      "781/781 [==============================] - 125s 160ms/step - loss: 0.7805 - accuracy: 0.7263 - val_loss: 1.5754 - val_accuracy: 0.5854\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.69780\n",
      "Epoch 10/100\n",
      "781/781 [==============================] - 125s 160ms/step - loss: 0.7375 - accuracy: 0.7439 - val_loss: 1.3145 - val_accuracy: 0.6552\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.69780\n",
      "Epoch 11/100\n",
      "781/781 [==============================] - 124s 159ms/step - loss: 0.7026 - accuracy: 0.7547 - val_loss: 1.6132 - val_accuracy: 0.6050\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.69780\n",
      "Epoch 12/100\n",
      "781/781 [==============================] - 124s 159ms/step - loss: 0.6798 - accuracy: 0.7638 - val_loss: 0.6869 - val_accuracy: 0.7797\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.69780 to 0.77970, saving model to model5_weights.best.hdf5\n",
      "Epoch 13/100\n",
      "781/781 [==============================] - 125s 160ms/step - loss: 0.6541 - accuracy: 0.7721 - val_loss: 1.0733 - val_accuracy: 0.6972\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.77970\n",
      "Epoch 14/100\n",
      "781/781 [==============================] - 125s 160ms/step - loss: 0.6308 - accuracy: 0.7798 - val_loss: 1.0946 - val_accuracy: 0.7073\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.77970\n",
      "Epoch 15/100\n",
      "781/781 [==============================] - 124s 159ms/step - loss: 0.6116 - accuracy: 0.7886 - val_loss: 0.6905 - val_accuracy: 0.7832\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.77970 to 0.78320, saving model to model5_weights.best.hdf5\n",
      "Epoch 16/100\n",
      "781/781 [==============================] - 124s 159ms/step - loss: 0.5951 - accuracy: 0.7928 - val_loss: 1.1738 - val_accuracy: 0.6919\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.78320\n",
      "Epoch 17/100\n",
      "781/781 [==============================] - 125s 160ms/step - loss: 0.5798 - accuracy: 0.7982 - val_loss: 0.7496 - val_accuracy: 0.7758\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.78320\n",
      "Epoch 18/100\n",
      "781/781 [==============================] - 125s 160ms/step - loss: 0.5659 - accuracy: 0.8046 - val_loss: 0.6886 - val_accuracy: 0.7975\n",
      "\n",
      "Epoch 00018: val_accuracy improved from 0.78320 to 0.79750, saving model to model5_weights.best.hdf5\n",
      "Epoch 19/100\n",
      "781/781 [==============================] - 125s 160ms/step - loss: 0.5497 - accuracy: 0.8112 - val_loss: 0.8661 - val_accuracy: 0.7550\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.79750\n",
      "Epoch 20/100\n",
      "781/781 [==============================] - 124s 159ms/step - loss: 0.5350 - accuracy: 0.8157 - val_loss: 1.1197 - val_accuracy: 0.7082\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.79750\n",
      "Epoch 21/100\n",
      "781/781 [==============================] - 125s 160ms/step - loss: 0.5278 - accuracy: 0.8173 - val_loss: 0.6811 - val_accuracy: 0.7966\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.79750\n",
      "Epoch 22/100\n",
      "781/781 [==============================] - 125s 159ms/step - loss: 0.5154 - accuracy: 0.8207 - val_loss: 0.7040 - val_accuracy: 0.7911\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.79750\n",
      "Epoch 23/100\n",
      "781/781 [==============================] - 125s 160ms/step - loss: 0.5016 - accuracy: 0.8256 - val_loss: 0.6738 - val_accuracy: 0.8055\n",
      "\n",
      "Epoch 00023: val_accuracy improved from 0.79750 to 0.80550, saving model to model5_weights.best.hdf5\n",
      "Epoch 24/100\n",
      "781/781 [==============================] - 124s 159ms/step - loss: 0.4982 - accuracy: 0.8278 - val_loss: 1.3099 - val_accuracy: 0.7262\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.80550\n",
      "Epoch 25/100\n",
      "781/781 [==============================] - 125s 160ms/step - loss: 0.4934 - accuracy: 0.8297 - val_loss: 0.5844 - val_accuracy: 0.8245\n",
      "\n",
      "Epoch 00025: val_accuracy improved from 0.80550 to 0.82450, saving model to model5_weights.best.hdf5\n",
      "Epoch 26/100\n",
      "781/781 [==============================] - 125s 159ms/step - loss: 0.4094 - accuracy: 0.8584 - val_loss: 0.4688 - val_accuracy: 0.8598\n",
      "\n",
      "Epoch 00026: val_accuracy improved from 0.82450 to 0.85980, saving model to model5_weights.best.hdf5\n",
      "Epoch 27/100\n",
      "781/781 [==============================] - 124s 159ms/step - loss: 0.3893 - accuracy: 0.8632 - val_loss: 0.4260 - val_accuracy: 0.8694\n",
      "\n",
      "Epoch 00027: val_accuracy improved from 0.85980 to 0.86940, saving model to model5_weights.best.hdf5\n",
      "Epoch 28/100\n",
      "781/781 [==============================] - 125s 160ms/step - loss: 0.3821 - accuracy: 0.8683 - val_loss: 0.4430 - val_accuracy: 0.8650\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.86940\n",
      "Epoch 29/100\n",
      "781/781 [==============================] - 124s 159ms/step - loss: 0.3752 - accuracy: 0.8703 - val_loss: 0.4483 - val_accuracy: 0.8640\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.86940\n",
      "Epoch 30/100\n",
      "781/781 [==============================] - 125s 159ms/step - loss: 0.3675 - accuracy: 0.8719 - val_loss: 0.4330 - val_accuracy: 0.8685\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.86940\n",
      "Epoch 31/100\n",
      "781/781 [==============================] - 124s 159ms/step - loss: 0.3609 - accuracy: 0.8746 - val_loss: 0.4285 - val_accuracy: 0.8714\n",
      "\n",
      "Epoch 00031: val_accuracy improved from 0.86940 to 0.87140, saving model to model5_weights.best.hdf5\n",
      "Epoch 32/100\n",
      "781/781 [==============================] - 124s 159ms/step - loss: 0.3572 - accuracy: 0.8765 - val_loss: 0.4048 - val_accuracy: 0.8776\n",
      "\n",
      "Epoch 00032: val_accuracy improved from 0.87140 to 0.87760, saving model to model5_weights.best.hdf5\n",
      "Epoch 33/100\n",
      "781/781 [==============================] - 124s 159ms/step - loss: 0.3538 - accuracy: 0.8764 - val_loss: 0.4468 - val_accuracy: 0.8666\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.87760\n",
      "Epoch 34/100\n",
      "781/781 [==============================] - 124s 159ms/step - loss: 0.3451 - accuracy: 0.8806 - val_loss: 0.4183 - val_accuracy: 0.8751\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.87760\n",
      "Epoch 35/100\n",
      "781/781 [==============================] - 125s 160ms/step - loss: 0.3463 - accuracy: 0.8809 - val_loss: 0.4134 - val_accuracy: 0.8743\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.87760\n",
      "Epoch 36/100\n",
      "781/781 [==============================] - 125s 160ms/step - loss: 0.3373 - accuracy: 0.8829 - val_loss: 0.4375 - val_accuracy: 0.8720\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.87760\n",
      "Epoch 37/100\n",
      "781/781 [==============================] - 125s 160ms/step - loss: 0.3428 - accuracy: 0.8805 - val_loss: 0.4091 - val_accuracy: 0.8754\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.87760\n",
      "Epoch 38/100\n",
      "781/781 [==============================] - 125s 160ms/step - loss: 0.3376 - accuracy: 0.8825 - val_loss: 0.3819 - val_accuracy: 0.8815\n",
      "\n",
      "Epoch 00038: val_accuracy improved from 0.87760 to 0.88150, saving model to model5_weights.best.hdf5\n",
      "Epoch 39/100\n",
      "781/781 [==============================] - 125s 160ms/step - loss: 0.3375 - accuracy: 0.8821 - val_loss: 0.4721 - val_accuracy: 0.8637\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.88150\n",
      "Epoch 40/100\n",
      "781/781 [==============================] - 125s 160ms/step - loss: 0.3339 - accuracy: 0.8854 - val_loss: 0.4030 - val_accuracy: 0.8788\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.88150\n",
      "Epoch 41/100\n",
      "781/781 [==============================] - 125s 160ms/step - loss: 0.3334 - accuracy: 0.8832 - val_loss: 0.4245 - val_accuracy: 0.8726\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.88150\n",
      "Epoch 42/100\n",
      "781/781 [==============================] - 125s 160ms/step - loss: 0.3289 - accuracy: 0.8873 - val_loss: 0.4051 - val_accuracy: 0.8773\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.88150\n",
      "Epoch 43/100\n",
      "781/781 [==============================] - 125s 160ms/step - loss: 0.3271 - accuracy: 0.8861 - val_loss: 0.4003 - val_accuracy: 0.8798\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.88150\n",
      "Epoch 44/100\n",
      "781/781 [==============================] - 125s 160ms/step - loss: 0.3262 - accuracy: 0.8862 - val_loss: 0.4186 - val_accuracy: 0.8755\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.88150\n",
      "Epoch 45/100\n",
      "781/781 [==============================] - 124s 159ms/step - loss: 0.3253 - accuracy: 0.8862 - val_loss: 0.4137 - val_accuracy: 0.8778\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.88150\n",
      "Epoch 46/100\n",
      "781/781 [==============================] - 124s 159ms/step - loss: 0.3198 - accuracy: 0.8879 - val_loss: 0.3992 - val_accuracy: 0.8838\n",
      "\n",
      "Epoch 00046: val_accuracy improved from 0.88150 to 0.88380, saving model to model5_weights.best.hdf5\n",
      "Epoch 47/100\n",
      "781/781 [==============================] - 125s 160ms/step - loss: 0.3146 - accuracy: 0.8895 - val_loss: 0.3991 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.88380\n",
      "Epoch 48/100\n",
      "781/781 [==============================] - 125s 159ms/step - loss: 0.3127 - accuracy: 0.8908 - val_loss: 0.3981 - val_accuracy: 0.8810\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.88380\n",
      "Epoch 49/100\n",
      "781/781 [==============================] - 125s 160ms/step - loss: 0.3180 - accuracy: 0.8898 - val_loss: 0.4189 - val_accuracy: 0.8791\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.88380\n",
      "Epoch 50/100\n",
      "781/781 [==============================] - 125s 160ms/step - loss: 0.3189 - accuracy: 0.8886 - val_loss: 0.4156 - val_accuracy: 0.8764\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.88380\n",
      "Epoch 51/100\n",
      "781/781 [==============================] - 124s 159ms/step - loss: 0.3109 - accuracy: 0.8916 - val_loss: 0.3908 - val_accuracy: 0.8856\n",
      "\n",
      "Epoch 00051: val_accuracy improved from 0.88380 to 0.88560, saving model to model5_weights.best.hdf5\n",
      "Epoch 52/100\n",
      "781/781 [==============================] - 124s 159ms/step - loss: 0.3118 - accuracy: 0.8902 - val_loss: 0.3922 - val_accuracy: 0.8845\n",
      "\n",
      "Epoch 00052: val_accuracy did not improve from 0.88560\n",
      "Epoch 53/100\n",
      "781/781 [==============================] - 124s 158ms/step - loss: 0.3063 - accuracy: 0.8922 - val_loss: 0.3903 - val_accuracy: 0.8857\n",
      "\n",
      "Epoch 00053: val_accuracy improved from 0.88560 to 0.88570, saving model to model5_weights.best.hdf5\n",
      "Epoch 54/100\n",
      "781/781 [==============================] - 124s 159ms/step - loss: 0.3006 - accuracy: 0.8950 - val_loss: 0.3903 - val_accuracy: 0.8863\n",
      "\n",
      "Epoch 00054: val_accuracy improved from 0.88570 to 0.88630, saving model to model5_weights.best.hdf5\n",
      "Epoch 55/100\n",
      "781/781 [==============================] - 124s 158ms/step - loss: 0.3004 - accuracy: 0.8947 - val_loss: 0.3926 - val_accuracy: 0.8850\n",
      "\n",
      "Epoch 00055: val_accuracy did not improve from 0.88630\n",
      "Epoch 56/100\n",
      "781/781 [==============================] - 124s 159ms/step - loss: 0.3010 - accuracy: 0.8934 - val_loss: 0.3814 - val_accuracy: 0.8881\n",
      "\n",
      "Epoch 00056: val_accuracy improved from 0.88630 to 0.88810, saving model to model5_weights.best.hdf5\n",
      "Epoch 57/100\n",
      "781/781 [==============================] - 124s 159ms/step - loss: 0.2998 - accuracy: 0.8943 - val_loss: 0.3942 - val_accuracy: 0.8854\n",
      "\n",
      "Epoch 00057: val_accuracy did not improve from 0.88810\n",
      "Epoch 58/100\n",
      "781/781 [==============================] - 124s 159ms/step - loss: 0.3010 - accuracy: 0.8955 - val_loss: 0.3848 - val_accuracy: 0.8866\n",
      "\n",
      "Epoch 00058: val_accuracy did not improve from 0.88810\n",
      "Epoch 59/100\n",
      "781/781 [==============================] - 124s 159ms/step - loss: 0.3007 - accuracy: 0.8941 - val_loss: 0.3823 - val_accuracy: 0.8879\n",
      "\n",
      "Epoch 00059: val_accuracy did not improve from 0.88810\n",
      "Epoch 60/100\n",
      "781/781 [==============================] - 124s 158ms/step - loss: 0.3023 - accuracy: 0.8946 - val_loss: 0.3821 - val_accuracy: 0.8867\n",
      "\n",
      "Epoch 00060: val_accuracy did not improve from 0.88810\n",
      "Epoch 61/100\n",
      "781/781 [==============================] - 124s 159ms/step - loss: 0.2990 - accuracy: 0.8958 - val_loss: 0.3833 - val_accuracy: 0.8874\n",
      "\n",
      "Epoch 00061: val_accuracy did not improve from 0.88810\n",
      "Epoch 62/100\n",
      "781/781 [==============================] - 125s 159ms/step - loss: 0.2999 - accuracy: 0.8951 - val_loss: 0.3818 - val_accuracy: 0.8864\n",
      "\n",
      "Epoch 00062: val_accuracy did not improve from 0.88810\n",
      "Epoch 63/100\n",
      "781/781 [==============================] - 124s 159ms/step - loss: 0.3023 - accuracy: 0.8949 - val_loss: 0.3909 - val_accuracy: 0.8843\n",
      "\n",
      "Epoch 00063: val_accuracy did not improve from 0.88810\n",
      "Epoch 64/100\n",
      "781/781 [==============================] - 124s 158ms/step - loss: 0.3020 - accuracy: 0.8942 - val_loss: 0.3879 - val_accuracy: 0.8865\n",
      "\n",
      "Epoch 00064: val_accuracy did not improve from 0.88810\n",
      "Epoch 65/100\n",
      "781/781 [==============================] - 124s 159ms/step - loss: 0.2994 - accuracy: 0.8946 - val_loss: 0.3842 - val_accuracy: 0.8877\n",
      "\n",
      "Epoch 00065: val_accuracy did not improve from 0.88810\n",
      "Epoch 66/100\n",
      "781/781 [==============================] - 124s 159ms/step - loss: 0.3017 - accuracy: 0.8944 - val_loss: 0.3793 - val_accuracy: 0.8889\n",
      "\n",
      "Epoch 00066: val_accuracy improved from 0.88810 to 0.88890, saving model to model5_weights.best.hdf5\n",
      "Epoch 67/100\n",
      "781/781 [==============================] - 124s 159ms/step - loss: 0.2956 - accuracy: 0.8963 - val_loss: 0.3826 - val_accuracy: 0.8870\n",
      "\n",
      "Epoch 00067: val_accuracy did not improve from 0.88890\n",
      "Epoch 68/100\n",
      "781/781 [==============================] - 124s 159ms/step - loss: 0.3012 - accuracy: 0.8942 - val_loss: 0.3844 - val_accuracy: 0.8867\n",
      "\n",
      "Epoch 00068: val_accuracy did not improve from 0.88890\n",
      "Epoch 69/100\n",
      "781/781 [==============================] - 124s 159ms/step - loss: 0.2973 - accuracy: 0.8974 - val_loss: 0.3888 - val_accuracy: 0.8860\n",
      "\n",
      "Epoch 00069: val_accuracy did not improve from 0.88890\n",
      "Epoch 70/100\n",
      "781/781 [==============================] - 124s 159ms/step - loss: 0.2982 - accuracy: 0.8953 - val_loss: 0.3884 - val_accuracy: 0.8866\n",
      "\n",
      "Epoch 00070: val_accuracy did not improve from 0.88890\n",
      "Epoch 71/100\n",
      "781/781 [==============================] - 124s 159ms/step - loss: 0.2997 - accuracy: 0.8946 - val_loss: 0.3878 - val_accuracy: 0.8866\n",
      "\n",
      "Epoch 00071: val_accuracy did not improve from 0.88890\n",
      "Epoch 72/100\n",
      "781/781 [==============================] - 125s 160ms/step - loss: 0.2992 - accuracy: 0.8974 - val_loss: 0.3867 - val_accuracy: 0.8876\n",
      "\n",
      "Epoch 00072: val_accuracy did not improve from 0.88890\n",
      "Epoch 73/100\n",
      "781/781 [==============================] - 124s 159ms/step - loss: 0.2951 - accuracy: 0.8963 - val_loss: 0.3813 - val_accuracy: 0.8890\n",
      "\n",
      "Epoch 00073: val_accuracy improved from 0.88890 to 0.88900, saving model to model5_weights.best.hdf5\n",
      "Epoch 74/100\n",
      "781/781 [==============================] - 125s 159ms/step - loss: 0.2981 - accuracy: 0.8955 - val_loss: 0.3842 - val_accuracy: 0.8868\n",
      "\n",
      "Epoch 00074: val_accuracy did not improve from 0.88900\n",
      "Epoch 75/100\n",
      "781/781 [==============================] - 125s 159ms/step - loss: 0.2970 - accuracy: 0.8969 - val_loss: 0.3855 - val_accuracy: 0.8867\n",
      "\n",
      "Epoch 00075: val_accuracy did not improve from 0.88900\n",
      "Epoch 76/100\n",
      "781/781 [==============================] - 125s 159ms/step - loss: 0.2939 - accuracy: 0.8969 - val_loss: 0.3881 - val_accuracy: 0.8884\n",
      "\n",
      "Epoch 00076: val_accuracy did not improve from 0.88900\n",
      "Epoch 77/100\n",
      "781/781 [==============================] - 124s 159ms/step - loss: 0.2957 - accuracy: 0.8960 - val_loss: 0.3855 - val_accuracy: 0.8890\n",
      "\n",
      "Epoch 00077: val_accuracy did not improve from 0.88900\n",
      "Epoch 78/100\n",
      "781/781 [==============================] - 124s 159ms/step - loss: 0.2948 - accuracy: 0.8967 - val_loss: 0.3896 - val_accuracy: 0.8878\n",
      "\n",
      "Epoch 00078: val_accuracy did not improve from 0.88900\n",
      "Epoch 79/100\n",
      "781/781 [==============================] - 124s 159ms/step - loss: 0.2965 - accuracy: 0.8962 - val_loss: 0.3808 - val_accuracy: 0.8890\n",
      "\n",
      "Epoch 00079: val_accuracy did not improve from 0.88900\n",
      "Epoch 80/100\n",
      "781/781 [==============================] - 124s 159ms/step - loss: 0.2952 - accuracy: 0.8980 - val_loss: 0.3862 - val_accuracy: 0.8879\n",
      "\n",
      "Epoch 00080: val_accuracy did not improve from 0.88900\n",
      "Epoch 81/100\n",
      "781/781 [==============================] - 124s 159ms/step - loss: 0.2949 - accuracy: 0.8969 - val_loss: 0.3879 - val_accuracy: 0.8863\n",
      "\n",
      "Epoch 00081: val_accuracy did not improve from 0.88900\n",
      "Epoch 82/100\n",
      "781/781 [==============================] - 124s 159ms/step - loss: 0.2986 - accuracy: 0.8959 - val_loss: 0.3815 - val_accuracy: 0.8891\n",
      "\n",
      "Epoch 00082: val_accuracy improved from 0.88900 to 0.88910, saving model to model5_weights.best.hdf5\n",
      "Epoch 83/100\n",
      "781/781 [==============================] - 125s 160ms/step - loss: 0.2974 - accuracy: 0.8958 - val_loss: 0.3891 - val_accuracy: 0.8873\n",
      "\n",
      "Epoch 00083: val_accuracy did not improve from 0.88910\n",
      "Epoch 84/100\n",
      "781/781 [==============================] - 124s 159ms/step - loss: 0.2946 - accuracy: 0.8971 - val_loss: 0.3838 - val_accuracy: 0.8889\n",
      "\n",
      "Epoch 00084: val_accuracy did not improve from 0.88910\n",
      "Epoch 85/100\n",
      "781/781 [==============================] - 124s 159ms/step - loss: 0.2971 - accuracy: 0.8969 - val_loss: 0.3807 - val_accuracy: 0.8887\n",
      "\n",
      "Epoch 00085: val_accuracy did not improve from 0.88910\n",
      "Epoch 86/100\n",
      "781/781 [==============================] - 125s 159ms/step - loss: 0.2908 - accuracy: 0.8973 - val_loss: 0.3842 - val_accuracy: 0.8889\n",
      "\n",
      "Epoch 00086: val_accuracy did not improve from 0.88910\n",
      "Epoch 87/100\n",
      "781/781 [==============================] - 124s 159ms/step - loss: 0.2960 - accuracy: 0.8954 - val_loss: 0.3871 - val_accuracy: 0.8878\n",
      "\n",
      "Epoch 00087: val_accuracy did not improve from 0.88910\n",
      "Epoch 88/100\n",
      "781/781 [==============================] - 125s 160ms/step - loss: 0.2933 - accuracy: 0.8969 - val_loss: 0.3809 - val_accuracy: 0.8880\n",
      "\n",
      "Epoch 00088: val_accuracy did not improve from 0.88910\n",
      "Epoch 89/100\n",
      "781/781 [==============================] - 124s 159ms/step - loss: 0.2929 - accuracy: 0.8979 - val_loss: 0.3799 - val_accuracy: 0.8892\n",
      "\n",
      "Epoch 00089: val_accuracy improved from 0.88910 to 0.88920, saving model to model5_weights.best.hdf5\n",
      "Epoch 90/100\n",
      "781/781 [==============================] - 124s 159ms/step - loss: 0.2910 - accuracy: 0.8989 - val_loss: 0.3807 - val_accuracy: 0.8908\n",
      "\n",
      "Epoch 00090: val_accuracy improved from 0.88920 to 0.89080, saving model to model5_weights.best.hdf5\n",
      "Epoch 91/100\n",
      "781/781 [==============================] - 124s 159ms/step - loss: 0.2920 - accuracy: 0.8975 - val_loss: 0.3795 - val_accuracy: 0.8902\n",
      "\n",
      "Epoch 00091: val_accuracy did not improve from 0.89080\n",
      "Epoch 92/100\n",
      "781/781 [==============================] - 124s 159ms/step - loss: 0.2921 - accuracy: 0.8981 - val_loss: 0.3800 - val_accuracy: 0.8899\n",
      "\n",
      "Epoch 00092: val_accuracy did not improve from 0.89080\n",
      "Epoch 93/100\n",
      "781/781 [==============================] - 125s 160ms/step - loss: 0.2974 - accuracy: 0.8960 - val_loss: 0.3842 - val_accuracy: 0.8883\n",
      "\n",
      "Epoch 00093: val_accuracy did not improve from 0.89080\n",
      "Epoch 94/100\n",
      "781/781 [==============================] - 124s 159ms/step - loss: 0.2936 - accuracy: 0.8975 - val_loss: 0.3880 - val_accuracy: 0.8876\n",
      "\n",
      "Epoch 00094: val_accuracy did not improve from 0.89080\n",
      "Epoch 95/100\n",
      "781/781 [==============================] - 124s 159ms/step - loss: 0.2912 - accuracy: 0.8979 - val_loss: 0.3797 - val_accuracy: 0.8896\n",
      "\n",
      "Epoch 00095: val_accuracy did not improve from 0.89080\n",
      "Epoch 96/100\n",
      "781/781 [==============================] - 124s 159ms/step - loss: 0.2941 - accuracy: 0.8977 - val_loss: 0.3795 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00096: val_accuracy did not improve from 0.89080\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f175e69a550>"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model5.fit(aug.flow(X_train,y_train,batch_size=batch_size),epochs=nb_epoch,batch_size=batch_size,verbose=1,\n",
    "           steps_per_epoch=(len(X_train)//batch_size),\n",
    "           callbacks=[reduce_lr,lr_scheduler,csv_logger,early_stop,model_checkpoint],\n",
    "           validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "kADL0zj2yzJJ",
    "outputId": "0322cc59-5f28-4a6c-da70-81b9064f871c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>loss</th>\n",
       "      <th>lr</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.286867</td>\n",
       "      <td>1.953920</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.3451</td>\n",
       "      <td>1.860124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.421540</td>\n",
       "      <td>1.574372</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.2778</td>\n",
       "      <td>2.734015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.517222</td>\n",
       "      <td>1.333009</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.3612</td>\n",
       "      <td>2.852820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.579842</td>\n",
       "      <td>1.169290</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.5871</td>\n",
       "      <td>1.334862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.622016</td>\n",
       "      <td>1.055502</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.5794</td>\n",
       "      <td>1.494813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>91</td>\n",
       "      <td>0.898130</td>\n",
       "      <td>0.292132</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.8899</td>\n",
       "      <td>0.380016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>92</td>\n",
       "      <td>0.896007</td>\n",
       "      <td>0.297427</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.8883</td>\n",
       "      <td>0.384248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>93</td>\n",
       "      <td>0.897529</td>\n",
       "      <td>0.293597</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.8876</td>\n",
       "      <td>0.387959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>94</td>\n",
       "      <td>0.897889</td>\n",
       "      <td>0.291213</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.8896</td>\n",
       "      <td>0.379663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>95</td>\n",
       "      <td>0.897749</td>\n",
       "      <td>0.294055</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.8900</td>\n",
       "      <td>0.379485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch  accuracy      loss      lr  val_accuracy  val_loss\n",
       "0       0  0.286867  1.953920  0.0100        0.3451  1.860124\n",
       "1       1  0.421540  1.574372  0.0100        0.2778  2.734015\n",
       "2       2  0.517222  1.333009  0.0100        0.3612  2.852820\n",
       "3       3  0.579842  1.169290  0.0100        0.5871  1.334862\n",
       "4       4  0.622016  1.055502  0.0100        0.5794  1.494813\n",
       "..    ...       ...       ...     ...           ...       ...\n",
       "91     91  0.898130  0.292132  0.0001        0.8899  0.380016\n",
       "92     92  0.896007  0.297427  0.0001        0.8883  0.384248\n",
       "93     93  0.897529  0.293597  0.0001        0.8876  0.387959\n",
       "94     94  0.897889  0.291213  0.0001        0.8896  0.379663\n",
       "95     95  0.897749  0.294055  0.0001        0.8900  0.379485\n",
       "\n",
       "[96 rows x 6 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "training_log = pd.read_csv('/content/training_model5.log')\n",
    "training_log.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jyjXikkiyzGM",
    "outputId": "dcb51723-9c45-453a-c49b-f8eb436fa072"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created and weights loaded from file\n"
     ]
    }
   ],
   "source": [
    "model5.load_weights('/content/model5_weights.best.hdf5')\n",
    "model5.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "print(\"Model created and weights loaded from file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fEMtpNatyzDM",
    "outputId": "637d6d59-21e9-4f11-fa22-d9e345b4f651"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss =  0.3807081878185272\n",
      "Test accuracy =  0.8907999992370605\n"
     ]
    }
   ],
   "source": [
    "score = model5.evaluate(X_test,y_test,verbose=0)\n",
    "print(\"Test loss = \",score[0])\n",
    "print(\"Test accuracy = \",score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OUZaKCCe1Yi1"
   },
   "source": [
    "### 2.7 Plotting loss and accuracy of Model 5 above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "upWThdRIp36I"
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "VoMsej6Nyy84",
    "outputId": "a1161368-0e07-46fb-9a29-58ded34ec3b3"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#https://machinelearningmastery.com/display-deep-learning-model-training-history-in-keras/\n",
    "plt.plot(training_log['accuracy'])\n",
    "plt.plot(training_log['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','test'],loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "EePumR7uyy6Z",
    "outputId": "c0e85cef-eff9-4998-9da1-c1814541d5e9"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#https://machinelearningmastery.com/display-deep-learning-model-training-history-in-keras/\n",
    "plt.plot(training_log['loss'])\n",
    "plt.plot(training_log['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['train','test'],loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iT4Q8IEl1oVc"
   },
   "source": [
    "## 3. Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lfO5o9kFyy24",
    "outputId": "b3540ad3-8644-442b-e380-3d572c188545"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------+-------------+---------------+\n",
      "| Growth Rate | Compression | # of Blocks | Test Accuracy |\n",
      "+-------------+-------------+-------------+---------------+\n",
      "|      24     |     0.5     |      12     |     82.59     |\n",
      "|      32     |     0.7     |      12     |     87.99     |\n",
      "|      36     |     0.7     |      12     |     89.079    |\n",
      "+-------------+-------------+-------------+---------------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "x = PrettyTable()\n",
    "x.field_names = ['Growth Rate','Compression','# of Blocks','Test Accuracy']\n",
    "x.add_row([24,0.5,12,82.590])\n",
    "x.add_row([32,0.7,12,87.990])\n",
    "x.add_row([36,0.7,12,89.079])\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "R_MQi93hyy0C"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------+-------------+---------------+\n",
      "| Growth Rate | Compression | # of Blocks | Test Accuracy |\n",
      "+-------------+-------------+-------------+---------------+\n",
      "|      24     |     0.5     |      12     |     82.59     |\n",
      "|      32     |     0.7     |      12     |     87.99     |\n",
      "|      36     |     0.7     |      12     |     89.079    |\n",
      "+-------------+-------------+-------------+---------------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "x1 = PrettyTable()\n",
    "x1.field_names = ['Growth Rate','Compression','# of Blocks','Test Accuracy']\n",
    "x1.add_row([24,0.5,12,82.590])\n",
    "x1.add_row([32,0.7,12,87.990])\n",
    "x1.add_row([36,0.7,12,89.079])\n",
    "\n",
    "print(x1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q78J2HCfeTRX"
   },
   "source": [
    "__*Summary:*__\n",
    "\n",
    "1. I have used Keras callbacks to adjust the learning rate as per the performance of the model(ReduceLRonPlateau,LearningRate Sceduler).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "2. Increase in Growth rate along with an increase with compression rate has led to improvement in test accuracy scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LpBGMqq7eTO-"
   },
   "source": [
    "**Additional links and resuorces:**\n",
    "\n",
    "1.\t2016 DenseNet paper summary: https://www.youtube.com/watch?v=hSC_0S8Zf9s\n",
    "2. \tSeparable Depth wise convolutions: https://towardsdatascience.com/a-basic-introduction-to-separable-convolutions-b99ec3102728\n",
    "3. Review DenseNet image classification: https://towardsdatascience.com/review-densenet-image-classification-b6631a8ef803"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8KS-J_lreTMX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HeRovVjo_9W3"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DenseNet_CIFAR_Final.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
